{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccd66402-6093-40da-9db4-130d34570c2f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff48b688-9f34-490a-805c-c48e8b3ab3b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForTokenClassification, AutoTokenizer\n",
    "import torch\n",
    "from torch import nn \n",
    "import torch.nn.functional as F\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "from tqdm import tqdm\n",
    "from Bio import SeqIO\n",
    "from collections import Counter, defaultdict\n",
    "from multiprocessing.pool import ThreadPool\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\") \n",
    "\n",
    "\n",
    "path_fasta = f\"/home/conchae/prediction_depolymerase_tropism/prophage_prediction/depolymerase_decipher/15122022_session/part_III_ptA/input_db/all_prophage_proteins.db.fasta\"\n",
    "path_work = f\"/home/conchae/prediction_depolymerase_tropism/prophage_prediction/depolymerase_decipher/ficheros_28032023\"\n",
    "\n",
    "\n",
    "# *********************************************************************\n",
    "# Define and load DepoScope :\n",
    "esm2_model_path = f\"/home/conchae/PhageDepo_pdb/script_files/esm2_t12_35M_UR50D-finetuned-depolymerase.labels_4/checkpoint-6015\"\n",
    "DpoDetection_path = f\"/home/conchae/PhageDepo_pdb/DepoDetection.T12.4Labels.1908.model\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(esm2_model_path)\n",
    "esm2_finetuned = AutoModelForTokenClassification.from_pretrained(esm2_model_path)\n",
    "\n",
    "class Dpo_classifier(nn.Module):\n",
    "    def __init__(self, pretrained_model):\n",
    "        super(Dpo_classifier, self).__init__()\n",
    "        self.max_length = 1024\n",
    "        self.pretrained_model = pretrained_model\n",
    "        self.conv1 = nn.Conv1d(1, 64, kernel_size=5, stride=1)  # Convolutional layer\n",
    "        self.conv2 = nn.Conv1d(64, 128, kernel_size=5, stride=1)  # Convolutional layer\n",
    "        self.fc1 = nn.Linear(128 * (self.max_length - 2 * (5 - 1)), 32)  # calculate the output shape after 2 conv layers\n",
    "        self.classifier = nn.Linear(32, 1)  # Binary classification\n",
    "\n",
    "    def make_prediction(self, fasta_txt):\n",
    "        input_ids = tokenizer.encode(fasta_txt, truncation=True, return_tensors='pt')\n",
    "        with torch.no_grad():\n",
    "            outputs = self.pretrained_model(input_ids)\n",
    "            probs = torch.nn.functional.softmax(outputs.logits, dim=-1)\n",
    "            token_probs, token_ids = torch.max(probs, dim=-1)            \n",
    "            tokens = token_ids.view(1, -1) # ensure 2D shape\n",
    "            return tokens\n",
    "\n",
    "    def pad_or_truncate(self, tokens):\n",
    "        if tokens.size(1) < self.max_length:\n",
    "            tokens = F.pad(tokens, (0, self.max_length - tokens.size(1)))\n",
    "        elif tokens.size(1) > self.max_length:\n",
    "            tokens = tokens[:, :self.max_length]\n",
    "        return tokens\n",
    "\n",
    "    def forward(self, sequences):\n",
    "        batch_size = len(sequences)\n",
    "        tokens_batch = []\n",
    "        for seq in sequences:\n",
    "            tokens = self.make_prediction(seq)\n",
    "            tokens = self.pad_or_truncate(tokens)\n",
    "            tokens_batch.append(tokens)\n",
    "        \n",
    "        outputs = torch.cat(tokens_batch).view(batch_size, 1, self.max_length)  # ensure 3D shape\n",
    "        outputs = outputs.float()  # Convert to float\n",
    "        \n",
    "        out = F.relu(self.conv1(outputs))\n",
    "        out = F.relu(self.conv2(out))\n",
    "        out = out.view(batch_size, -1)  # Flatten the tensor\n",
    "        out = F.relu(self.fc1(out))\n",
    "        out = self.classifier(out)\n",
    "        return out, outputs\n",
    "\n",
    "model_classifier = Dpo_classifier(esm2_finetuned) # Create an instance of Dpo_classifier\n",
    "model_classifier.load_state_dict(torch.load(DpoDetection_path), strict = False) # Load the saved weights ; weird Error with some of the keys \n",
    "model_classifier.eval() # Set the model to evaluation mode for inference\n",
    "\n",
    "\n",
    "# *********************************************************************\n",
    "# Useful functions :\n",
    "\n",
    "def predict_sequence(model, sequence):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        sequence = [sequence]  # Wrap the sequence in a list to match the model's input format\n",
    "        outputs, sequence_outputs = model(sequence)\n",
    "        probas = torch.sigmoid(outputs)  # Apply sigmoid activation for binary classification\n",
    "        predictions = (probas > 0.5).float()  # Convert probabilities to binary predictions\n",
    "        sequence_outputs_list = sequence_outputs.cpu().numpy().tolist()[0][0]\n",
    "        prob_predicted = probas[0].item()\n",
    "        return (predictions.item(), prob_predicted), sequence_outputs_list\n",
    "\n",
    "\n",
    "def find_longest_non_zero_suite_with_n_zeros(lst, n):\n",
    "    # Initialize variables to keep track of the longest suite\n",
    "    longest_start, longest_end = 0, 0\n",
    "    longest_length = 0\n",
    "    # Initialize variables to keep track of the current suite\n",
    "    current_start = 0\n",
    "    current_length = 0\n",
    "    current_zeros = 0\n",
    "    for i, num in enumerate(lst):\n",
    "        if num == 0:\n",
    "            # Increment the count of zeros in the current suite\n",
    "            current_zeros += 1\n",
    "            # If the number of zeros exceeds n, update the current start index and length\n",
    "            while current_zeros > n:\n",
    "                if lst[current_start] == 0:\n",
    "                    current_zeros -= 1\n",
    "                current_start += 1\n",
    "                current_length -= 1\n",
    "        # Increment the length of the current suite\n",
    "        current_length += 1\n",
    "        # Check if the current suite is longer than the longest suite found so far\n",
    "        if current_length > longest_length:\n",
    "            longest_start = current_start\n",
    "            longest_end = i\n",
    "            longest_length = current_length\n",
    "    return longest_start, longest_end\n",
    "    \n",
    "\n",
    "# *********************************************************************\n",
    "# Load the sequences into a dictionary :\n",
    "fasta_seqs = SeqIO.parse(path_fasta , \"fasta\")\n",
    "dico_seq = defaultdict(list)\n",
    "for record in fasta_seqs:\n",
    "    tmp_prot_name = record.id\n",
    "    sequence = str(record.seq)\n",
    "    if len(sequence) >= 200 :\n",
    "        dico_seq[sequence].append(tmp_prot_name)\n",
    "\n",
    "\n",
    "# *********************************************************************\n",
    "# Make the predictions : \n",
    "def run_predictions(item) : \n",
    "    sequence , prot_names = item[0] , item[1]\n",
    "    prediction, sequence_outputs = predict_sequence(model_classifier, sequence)\n",
    "    if prediction[0] == 1 :\n",
    "        start , end = find_longest_non_zero_suite_with_n_zeros(sequence_outputs, 10)\n",
    "        with open(f\"{path_work}/Anubis_return.predictions.0709.tsv\" , \"w\") as outfile :\n",
    "            for _,prot in enumerate(prot_names) :\n",
    "                outfile.write(f\"{prot}\\t{start}\\t{end}\\t{sequence[int(start) : int(end)]}\\t{sequence}\\n\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    RUN = list(map(run_predictions , list(dico_seq.items())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aa18716-f2ec-49dc-a6d7-243d169d97a6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:torch_geometric]",
   "language": "python",
   "name": "conda-env-torch_geometric-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
