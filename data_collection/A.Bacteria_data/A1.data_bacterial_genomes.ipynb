{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1286af63-9d2b-4913-9bb8-e6381bd9d3d8",
   "metadata": {},
   "source": [
    "# Collecting and processing the Klebsiella genomic data\n",
    "***\n",
    "### (I) Collecting the genomic data of Klebsiella genomes (run_singularity)\n",
    "### (II) Running Kleborate on fasta (run_kleborate_on_fasta)\n",
    "### (III) Genetic annotation of genomes correctly annotated (run_prokka_annotation)\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be88382f-2572-4d08-a423-473d1cf847a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import os \n",
    "import random\n",
    "\n",
    "def run_singularity(img_path: str, t_ncbi: int, output_path: str):\n",
    "    \"\"\"\n",
    "    Runs the singularity command with specified image, tropism value, and output directory.\n",
    "\n",
    "    Parameters:\n",
    "    img_path : Path to the singularity image /panacota.img.\n",
    "    t_ncbi : the taxid provided by the NCBI for the species you want to download\n",
    "    output_path : Output directory path. In there, A folder called refseq/bacteria containing: \n",
    "    1 folder per assembly and, inside, the assembly sequence in fasta.gz format, and the MD5SUMS of this file.\n",
    "    \n",
    "    Returns:\n",
    "    None: Outputs will be saved in the specified output directory.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        command = [\n",
    "            \"singularity\", \"run\", img_path, \n",
    "            \"prepare\", \"-T\", str(t_ncbi), \n",
    "            \"-o\", output_path\n",
    "        ]\n",
    "        result = subprocess.run(command, check=True, capture_output=True, text=True)\n",
    "        print(result.stdout)  \n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"Error occurred while running the command: {e.stderr}\")\n",
    "        \n",
    "\n",
    "def run_kleborate_on_fasta(path_klebsiella: str):\n",
    "    \"\"\"\n",
    "    Runs Kleborate on .fna files found in the Database_init folder for each species in the provided path.\n",
    "    Parameters:\n",
    "    path_klebsiella (str): The base path containing species directories with FASTA files.\n",
    "    Returns:\n",
    "    None: Outputs are saved in their respective output directories.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        for specie in os.listdir(path_klebsiella):\n",
    "            specie_path = os.path.join(path_klebsiella, specie)\n",
    "            init_path = os.path.join(specie_path, \"Database_init\")\n",
    "            \n",
    "            # Ensure the Database_init directory exists\n",
    "            if not os.path.exists(init_path):\n",
    "                print(f\"Directory {init_path} does not exist. Skipping...\")\n",
    "                continue\n",
    "            \n",
    "            for fasta in os.listdir(init_path):\n",
    "                if fasta.endswith(\".fna\"):\n",
    "                    rep = \"_\".join(fasta.split(\"_\")[0:2])\n",
    "                    path_in = init_path\n",
    "                    path_out = os.path.join(specie_path, \"refseq\", \"bacteria\", rep)\n",
    "                    kaptive_out_file = os.path.join(path_out, f\"{rep}_Kaptive_out.txt\")\n",
    "                    \n",
    "                    if not os.path.isfile(kaptive_out_file):\n",
    "                        try:\n",
    "                            command = [\n",
    "                                \"kleborate\", \"--kaptive_k\", \n",
    "                                \"--kaptive_k_outfile\", kaptive_out_file, \n",
    "                                \"-a\", os.path.join(path_in, fasta)\n",
    "                            ]\n",
    "                            # Run kleborate command\n",
    "                            subprocess.run(command, check=True, capture_output=True, text=True)\n",
    "                            print(f\"Processed: {fasta}\")\n",
    "                        except subprocess.CalledProcessError as e:\n",
    "                            print(f\"Error while running kleborate on {fasta}: {e.stderr}\")\n",
    "                    else:\n",
    "                        print(f\"Output file {kaptive_out_file} already exists. Skipping...\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "\n",
    "        \n",
    "def process_kleborate_results(path_klebsiella: str, k_specie: dict):\n",
    "    \"\"\"\n",
    "    Processes Kleborate results and compiles information from various species into a single TSV file.\n",
    "\n",
    "    Parameters:\n",
    "    path_klebsiella (str): The base path containing species directories.\n",
    "    k_specie (dict): Dictionary mapping species codes to full species names.\n",
    "    \n",
    "    Returns:\n",
    "    None: Outputs are written to a kleborate_results_all.tsv file.\n",
    "    \"\"\"\n",
    "    output_file = os.path.join(path_klebsiella, \"kleborate_results_all.tsv\")\n",
    "    \n",
    "    try:\n",
    "        with open(output_file, \"w\") as outfile:\n",
    "            # Write the header line for the output file\n",
    "            outfile.write(\"Accession\\tSpecie\\tK-Serotype\\tConfidence\\tn Missing genes in K-Locus\\n\")\n",
    "            \n",
    "            for specie in os.listdir(path_klebsiella):\n",
    "                specie_path = os.path.join(path_klebsiella, specie)\n",
    "                \n",
    "                # Process only directories that start with 'k'\n",
    "                if specie.startswith(\"k\") and os.path.isdir(specie_path):\n",
    "                    info_out = \"\"\n",
    "                    \n",
    "                    # Look for the LSTINFO file in the species directory\n",
    "                    for file in os.listdir(specie_path):\n",
    "                        if file.startswith(\"LSTINFO\"):\n",
    "                            lstinfo_path = os.path.join(specie_path, file)\n",
    "                            with open(lstinfo_path, \"r\") as lstinfo_file:\n",
    "                                info_out = lstinfo_file.read()\n",
    "                    \n",
    "                    # Process each representative (rep) in the refseq/bacteria directory\n",
    "                    refseq_path = os.path.join(specie_path, \"refseq\", \"bacteria\")\n",
    "                    \n",
    "                    if not os.path.isdir(refseq_path):\n",
    "                        print(f\"Refseq directory not found for {specie}. Skipping...\")\n",
    "                        continue\n",
    "                    \n",
    "                    for rep in os.listdir(refseq_path):\n",
    "                        info_rep = \"\"\n",
    "                        \n",
    "                        # Match info_rep based on the rep name in the LSTINFO data\n",
    "                        for index, info in enumerate(info_out.split(\"\\n\")):\n",
    "                            if rep in info:\n",
    "                                info_rep = info\n",
    "                                break\n",
    "                        \n",
    "                        # Read the Kaptive output for the current rep\n",
    "                        kaptive_out_file = os.path.join(refseq_path, rep, f\"{rep}_Kaptive_out.txt\")\n",
    "                        \n",
    "                        if not os.path.isfile(kaptive_out_file):\n",
    "                            print(f\"Kaptive output file not found for {rep}. Skipping...\")\n",
    "                            continue\n",
    "                        \n",
    "                        with open(kaptive_out_file, \"r\") as kaptive_file:\n",
    "                            kaptive_out = kaptive_file.read().splitlines()\n",
    "                        \n",
    "                        # Parse the Kaptive output data\n",
    "                        if len(kaptive_out) < 2:\n",
    "                            print(f\"Incomplete Kaptive output for {rep}. Skipping...\")\n",
    "                            continue\n",
    "                        \n",
    "                        first_line = kaptive_out[0].split(\"\\t\")\n",
    "                        second_line = kaptive_out[1].split(\"\\t\")\n",
    "                        \n",
    "                        kaptive_dic = dict(zip(first_line, second_line))\n",
    "                        n_miss = len(kaptive_dic[\"Missing expected genes\"].split(\";\")) - 1\n",
    "                        \n",
    "                        # Only consider entries with medium or high confidence\n",
    "                        if kaptive_dic[\"Match confidence\"] not in [\"None\", \"Low\"]:\n",
    "                            # Write the relevant information to the output file\n",
    "                            outfile.write(f\"{rep}\\t{k_specie.get(specie, 'Unknown')}\\t\"\n",
    "                                          f\"{kaptive_dic['Best match locus']}\\t\"\n",
    "                                          f\"{kaptive_dic['Match confidence']}\\t\"\n",
    "                                          f\"{n_miss}\\n\")\n",
    "                            print(f\"Processed: {rep}\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "\n",
    "\n",
    "def run_prokka_annotation(path_klebsiella: str, target_species: str = \"k_pneumoniae\"):\n",
    "    \"\"\"\n",
    "    Runs Prokka annotation on .fna files for a specific species in the Klebsiella dataset.\n",
    "\n",
    "    Parameters:\n",
    "    path_klebsiella : Base path containing species directories with FASTA files.\n",
    "    target_species : The species to run Prokka annotation for (default is k_pneumoniae).\n",
    "    \n",
    "    Returns:\n",
    "    None: Outputs will be written to the corresponding directories.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        for specie in os.listdir(path_klebsiella):\n",
    "            specie_path = os.path.join(path_klebsiella, specie)\n",
    "\n",
    "            # Process only the target species\n",
    "            if specie.startswith(\"k\") and specie == target_species:\n",
    "                db_init_path = os.path.join(specie_path, \"Database_init\")\n",
    "\n",
    "                # Ensure the Database_init directory exists\n",
    "                if not os.path.isdir(db_init_path):\n",
    "                    print(f\"Database_init directory not found for {specie}. Skipping...\")\n",
    "                    continue\n",
    "\n",
    "                # Select a random sample of .fna files in the directory\n",
    "                fasta_files = [f for f in os.listdir(db_init_path) if f.endswith(\".fna\")]\n",
    "                \n",
    "                for fasta in random.sample(fasta_files, len(fasta_files)):\n",
    "                    rep = \"_\".join(fasta.split(\"_\")[0:2])\n",
    "                    path_in = db_init_path\n",
    "                    path_out = os.path.join(specie_path, \"refseq\", \"bacteria\", rep)\n",
    "\n",
    "                    # Create output directory if it doesn't exist\n",
    "                    prokka_out_path = os.path.join(path_out, \"prokka_annotation\")\n",
    "                    if not os.path.isdir(prokka_out_path):\n",
    "                        os.makedirs(prokka_out_path, exist_ok=True)\n",
    "\n",
    "                        # Build and run the Prokka command\n",
    "                        prokka_command = [\n",
    "                            \"prokka\", os.path.join(path_in, fasta), \n",
    "                            \"--norrna\", \"--notrna\", \n",
    "                            \"--outdir\", prokka_out_path, \n",
    "                            \"--prefix\", rep, \n",
    "                            \"--compliant\", \"--force\", \n",
    "                            \"--cpus\", \"0\"\n",
    "                        ]\n",
    "\n",
    "                        try:\n",
    "                            # Run the Prokka annotation command\n",
    "                            subprocess.run(prokka_command, check=True, capture_output=True, text=True)\n",
    "                            print(f\"Prokka annotation completed for: {fasta}\")\n",
    "                        except subprocess.CalledProcessError as e:\n",
    "                            print(f\"Error running Prokka on {fasta}: {e.stderr}\")\n",
    "                    else:\n",
    "                        print(f\"Prokka annotation already exists for: {rep}. Skipping...\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a31c5f62-27b8-4987-891a-6909c2801e60",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(path_klebsiella: str, singularity_img_path: str, t_ncbi: int):\n",
    "    \"\"\"\n",
    "    Main function to run singularity, Kleborate, and Prokka annotation on Klebsiella species.\n",
    "\n",
    "    Parameters:\n",
    "    path_klebsiella : Base path containing species directories.\n",
    "    singularity_img_path : Path to the singularity image.\n",
    "    t_ncbi : NCBI taxid for the species to download.\n",
    "    \n",
    "    Returns:\n",
    "    None\n",
    "    \"\"\"\n",
    "    # Dictionary mapping Klebsiella species codes to full species names\n",
    "    k_specie = {\n",
    "        \"k_aerogenes\": \"Klebsiella aerogenes\",\n",
    "        \"k_africana\": \"Klebsiella africana\",\n",
    "        \"k_grimatii\": \"Klebsiella grimontii\",\n",
    "        \"k_huaxiensis\": \"Klebsiella huaxiensis\",\n",
    "        \"k_indica\": \"Klebsiella indica\",\n",
    "        \"k_michiganesis\": \"Klebsiella michiganensis\",\n",
    "        \"k_oxytoca\": \"Klebsiella oxytoca\",\n",
    "        \"k_pasteurii\": \"Klebsiella pasteurii\",\n",
    "        \"k_pneumoniae\": \"Klebsiella pneumoniae\",\n",
    "        \"k_quasipneumoniae\": \"Klebsiella quasipneumoniae\",\n",
    "        \"k_quasivariicola\": \"Klebsiella quasivariicola\",\n",
    "        \"k_spallanzanii\": \"Klebsiella spallanzanii\",\n",
    "        \"k_variicola\": \"Klebsiella variicola\"\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        # Step 1: Run the singularity command to prepare the environment\n",
    "        print(\"Running Singularity to prepare the dataset...\")\n",
    "        run_singularity(singularity_img_path, t_ncbi, path_klebsiella)\n",
    "        print(\"Singularity command completed successfully.\\n\")\n",
    "\n",
    "        # Step 2: Run Kleborate on the FASTA files in the Klebsiella dataset\n",
    "        print(\"Running Kleborate on FASTA files...\")\n",
    "        run_kleborate_on_fasta(path_klebsiella)\n",
    "        print(\"Kleborate analysis completed successfully.\\n\")\n",
    "        for specie in k_specie : \n",
    "            \n",
    "            # Step 3: Process the Kleborate results and compile them into a single TSV file\n",
    "            print(\"Processing Kleborate results...\")\n",
    "            process_kleborate_results(path_klebsiella, specie)\n",
    "            print(\"Kleborate results processed and saved successfully.\\n\")\n",
    "\n",
    "            # Step 4: Run Prokka annotation on the Klebsiella species of interest\n",
    "            print(\"Running Prokka annotation on FASTA files...\")\n",
    "            run_prokka_annotation(path_klebsiella, specie)\n",
    "            print(\"Prokka annotation completed successfully.\\n\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred during the main process: {e}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Path to the Klebsiella dataset\n",
    "    path_klebsiella = \"/home/conchae/prediction_depolymerase_tropism\"\n",
    "    # Path to the singularity image\n",
    "    singularity_img_path = \"/home/conchae/prediction_depolymerase_tropism/panacota.img\"\n",
    "    # NCBI taxid for the species to download (example value)\n",
    "    t_ncbi = 570  # Replace with the actual NCBI taxid\n",
    "    # Run the main function\n",
    "    main(path_klebsiella, singularity_img_path, t_ncbi)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:torch_geometric]",
   "language": "python",
   "name": "conda-env-torch_geometric-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
