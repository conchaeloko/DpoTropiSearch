{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3c99dec6-0c46-4eac-b5ed-40171726323e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from itertools import product\n",
    "import random\n",
    "from collections import Counter, defaultdict\n",
    "import warnings\n",
    "import logging\n",
    "import subprocess\n",
    "from multiprocessing.pool import ThreadPool\n",
    "import joblib\n",
    "\n",
    "# SCikitlearn modules :\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV, StratifiedKFold\n",
    "from sklearn.metrics import classification_report , roc_auc_score, matthews_corrcoef\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# Scipy modules : \n",
    "from scipy.stats import fisher_exact\n",
    "from statistics import mean\n",
    "\n",
    "\n",
    "PATH_WORK = \"/home/conchae/prediction_depolymerase_tropism/prophage_prediction/depolymerase_decipher/ficheros_28032023/Seqbased_model\"\n",
    "path_metrics = f\"{PATH_WORK}/metric_files\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec8cfd76-cc76-4a12-96ea-aefe724bd875",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Make the metrics files : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cc98749-c904-4d70-ac77-17e662966a09",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    df_info = pd.read_csv(f\"{PATH_WORK}/TropiGATv2.final_df_v2.tsv\", sep=\"\\t\", header=0)\n",
    "    df_prophages = df_info.drop_duplicates(subset=[\"Phage\"], keep=\"first\")\n",
    "    dico_prophage_info = {row[\"Phage\"]: {\"prophage_strain\": row[\"prophage_id\"], \"ancestor\": row[\"Infected_ancestor\"]} for _, row in df_prophages.iterrows()}\n",
    "    return df_info, dico_prophage_info\n",
    "\n",
    "def get_filtered_prophages(prophage, df_info, dico_prophage_info):\n",
    "    to_exclude = set()\n",
    "    to_keep = {prophage}\n",
    "    df_prophage_group = df_info[(df_info[\"prophage_id\"] == dico_prophage_info[prophage][\"prophage_strain\"]) & \n",
    "                                (df_info[\"Infected_ancestor\"] == dico_prophage_info[prophage][\"ancestor\"])]\n",
    "    \n",
    "    if len(df_prophage_group) > 1:\n",
    "        depo_set = set(df_prophage_group[df_prophage_group[\"Phage\"] == prophage][\"domain_seq\"].values)\n",
    "        combinations = [depo_set]\n",
    "        \n",
    "        for prophage_tmp in df_prophage_group[\"Phage\"].unique():\n",
    "            if prophage_tmp != prophage:\n",
    "                tmp_depo_set = set(df_prophage_group[df_prophage_group[\"Phage\"] == prophage_tmp][\"domain_seq\"].values)\n",
    "                if tmp_depo_set in combinations:\n",
    "                    to_exclude.add(prophage_tmp)\n",
    "                else:\n",
    "                    to_keep.add(prophage_tmp)\n",
    "                    combinations.append(tmp_depo_set)\n",
    "    \n",
    "    return df_prophage_group, to_exclude, to_keep\n",
    "\n",
    "def filter_prophages(df_info, dico_prophage_info):\n",
    "    good_prophages = set()\n",
    "    excluded_prophages = set()\n",
    "    for prophage in tqdm(dico_prophage_info.keys()):\n",
    "        if prophage not in excluded_prophages and prophage not in good_prophages:\n",
    "            _, excluded_members, kept_members = get_filtered_prophages(prophage, df_info, dico_prophage_info)\n",
    "            good_prophages.update(kept_members)\n",
    "            excluded_prophages.update(excluded_members)\n",
    "    df_info_filtered = df_info[df_info[\"Phage\"].isin(good_prophages)]\n",
    "    return df_info_filtered[~df_info_filtered[\"KL_type_LCA\"].str.contains(\"\\\\|\")]\n",
    "\n",
    "def ultrafilter_prophages(df_info):\n",
    "    duplicate_prophage = []\n",
    "    for kltype in df_info[\"KL_type_LCA\"].unique():\n",
    "        df_kl = df_info[df_info[\"KL_type_LCA\"] == kltype][[\"Phage\", \"domain_seq\"]]\n",
    "        set_sets_depo = []\n",
    "        for _, group in df_kl.groupby(\"Phage\"):\n",
    "            set_depo = frozenset(group[\"domain_seq\"].values)\n",
    "            if set_depo in set_sets_depo:\n",
    "                duplicate_prophage.extend(group[\"Phage\"])\n",
    "            else:\n",
    "                set_sets_depo.append(set_depo)\n",
    "    \n",
    "    return df_info[~df_info[\"Phage\"].isin(duplicate_prophage)]\n",
    "\n",
    "\n",
    "def get_mean_MCC(path_data_object):\n",
    "    try:\n",
    "        assert os.path.isfile(path_data_object)\n",
    "        data_object = joblib.load(path_data_object)\n",
    "        mcc_values = []\n",
    "        for i in data_object:\n",
    "            y_test = data_object[i][\"test_data\"][0].values\n",
    "            predictions = data_object[i][\"test_data\"][1]\n",
    "            mcc = matthews_corrcoef(y_test, predictions)\n",
    "            mcc_values.append(mcc)\n",
    "        del data_object \n",
    "        mean_mcc = mean(mcc_values)\n",
    "        return mean_mcc\n",
    "    except AssertionError:\n",
    "        raise FileNotFoundError(f\"File not found: {path_data_object}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfad3987-cda4-4876-884f-a862392cd6f4",
   "metadata": {},
   "source": [
    "> RF UF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d504e06-c43e-48c2-94cd-dee813459dc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_jobs = f\"{PATH_WORK}/RF_21122024_models_ultraF\"\n",
    "\n",
    "cluster_values = set([file.split(\"_\")[0] for file in os.listdir(path_jobs)])\n",
    "KLtypes = set([file.split(\"_RF_\")[1].split(\".full_data\")[0] for file in os.listdir(path_jobs)])\n",
    "\n",
    "KLtypes_paths = {kltype : [f\"{path_jobs}/{file}\" for file in os.listdir(path_jobs) if file.split(\"_RF_\")[1].split(\".full_data\")[0]==kltype]\n",
    "                for kltype in KLtypes}\n",
    "\n",
    "DF_info, dico_prophage_info = load_data()\n",
    "# UF or not ?\n",
    "DF_info_lvl_0 = ultrafilter_prophages(filter_prophages(DF_info, dico_prophage_info))\n",
    "#DF_info_lvl_0 = filter_prophages(DF_info, dico_prophage_info)\n",
    "\n",
    "dico_prophage_count = Counter(DF_info_lvl_0[\"KL_type_LCA\"])\n",
    "\n",
    "with open(f\"{path_metrics}/SEQ_based.RF__UF.prophages_metrics.tsv\", \"w\") as outfile :\n",
    "    for KLtype in tqdm(KLtypes_paths) : \n",
    "        for path in KLtypes_paths[KLtype] :\n",
    "            cl_value = path.split(\"/\")[-1].split(\"_RF\")[0]\n",
    "            mean_mcc = get_mean_MCC(path)\n",
    "            count_kltype = dico_prophage_count[KLtype]\n",
    "            outfile.write(f\"{KLtype}\\t{count_kltype}\\t{cl_value}\\t{mean_mcc}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "813ba1b6-a290-41c3-98b3-0ab83ee09b22",
   "metadata": {},
   "source": [
    "> RF :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e45a0df6-79ba-4c37-979c-1502663717c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_jobs = f\"{PATH_WORK}/RF_1302_models\"\n",
    "\n",
    "cluster_values = set([file.split(\"_\")[0] for file in os.listdir(path_jobs)])\n",
    "KLtypes = set([file.split(\"_RF_\")[1].split(\".full_data\")[0] for file in os.listdir(path_jobs)])\n",
    "\n",
    "KLtypes_paths = {kltype : [f\"{path_jobs}/{file}\" for file in os.listdir(path_jobs) if file.split(\"_RF_\")[1].split(\".full_data\")[0]==kltype]\n",
    "                for kltype in KLtypes}\n",
    "\n",
    "DF_info, dico_prophage_info = load_data()\n",
    "# UF or not ?\n",
    "#DF_info_lvl_0 = ultrafilter_prophages(filter_prophages(DF_info, dico_prophage_info))\n",
    "DF_info_lvl_0 = filter_prophages(DF_info, dico_prophage_info)\n",
    "\n",
    "dico_prophage_count = Counter(DF_info_lvl_0[\"KL_type_LCA\"])\n",
    "\n",
    "with open(f\"{path_metrics}/SEQ_based.RF.prophages_metrics.tsv\", \"w\") as outfile :\n",
    "    for KLtype in tqdm(KLtypes_paths) : \n",
    "        for path in KLtypes_paths[KLtype] :\n",
    "            cl_value = path.split(\"/\")[-1].split(\"_RF\")[0]\n",
    "            mean_mcc = get_mean_MCC(path)\n",
    "            count_kltype = dico_prophage_count[KLtype]\n",
    "            outfile.write(f\"{KLtype}\\t{count_kltype}\\t{cl_value}\\t{mean_mcc}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4fd7315-cb7b-49dc-9538-ed045247e3ca",
   "metadata": {},
   "source": [
    "> Lreg reg:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76c57510-c558-45c9-858e-1b8399b965f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_jobs = f\"{PATH_WORK}/LR_21122024_models\"\n",
    "\n",
    "cluster_values = set([file.split(\"_\")[0] for file in os.listdir(path_jobs)])\n",
    "KLtypes = set([file.split(\"_LogReg_\")[1].split(\".full_data\")[0] for file in os.listdir(path_jobs)])\n",
    "\n",
    "KLtypes_paths = {kltype : [f\"{path_jobs}/{file}\" for file in os.listdir(path_jobs) if file.split(\"_LogReg_\")[1].split(\".full_data\")[0]==kltype]\n",
    "                for kltype in KLtypes}\n",
    "\n",
    "DF_info, dico_prophage_info = load_data()\n",
    "# UF or not ?\n",
    "#DF_info_lvl_0 = ultrafilter_prophages(filter_prophages(DF_info, dico_prophage_info))\n",
    "DF_info_lvl_0 = filter_prophages(DF_info, dico_prophage_info)\n",
    "\n",
    "dico_prophage_count = Counter(DF_info_lvl_0[\"KL_type_LCA\"])\n",
    "\n",
    "with open(f\"{path_metrics}/SEQ_based.LogReg.prophages_metrics.tsv\", \"w\") as outfile :\n",
    "    for KLtype in tqdm(KLtypes_paths) : \n",
    "        for path in KLtypes_paths[KLtype] :\n",
    "            cl_value = path.split(\"/\")[-1].split(\"_RF\")[0]\n",
    "            mean_mcc = get_mean_MCC(path)\n",
    "            count_kltype = dico_prophage_count[KLtype]\n",
    "            outfile.write(f\"{KLtype}\\t{count_kltype}\\t{cl_value}\\t{mean_mcc}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50fb2a28-eb39-4ac8-9f55-76650134c690",
   "metadata": {},
   "source": [
    "> LogReg UF "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6a83c37-6950-4874-83c6-844fbd7eb477",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_jobs = f\"{PATH_WORK}/LR_21122024_models_ultraF\"\n",
    "\n",
    "cluster_values = set([file.split(\"_\")[0] for file in os.listdir(path_jobs)])\n",
    "KLtypes = set([file.split(\"_LogReg_\")[1].split(\".full_data\")[0] for file in os.listdir(path_jobs)])\n",
    "\n",
    "KLtypes_paths = {kltype : [f\"{path_jobs}/{file}\" for file in os.listdir(path_jobs) if file.split(\"_LogReg_\")[1].split(\".full_data\")[0]==kltype]\n",
    "                for kltype in KLtypes}\n",
    "\n",
    "DF_info, dico_prophage_info = load_data()\n",
    "# UF or not ?\n",
    "DF_info_lvl_0 = ultrafilter_prophages(filter_prophages(DF_info, dico_prophage_info))\n",
    "#DF_info_lvl_0 = filter_prophages(DF_info, dico_prophage_info)\n",
    "\n",
    "dico_prophage_count = Counter(DF_info_lvl_0[\"KL_type_LCA\"])\n",
    "\n",
    "with open(f\"{path_metrics}/SEQ_based.LogReg__UF.prophages_metrics.tsv\", \"w\") as outfile :\n",
    "    for KLtype in tqdm(KLtypes_paths) : \n",
    "        for path in KLtypes_paths[KLtype] :\n",
    "            cl_value = path.split(\"/\")[-1].split(\"_RF\")[0]\n",
    "            mean_mcc = get_mean_MCC(path)\n",
    "            count_kltype = dico_prophage_count[KLtype]\n",
    "            outfile.write(f\"{KLtype}\\t{count_kltype}\\t{cl_value}\\t{mean_mcc}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bb56fc1-2197-4767-82d2-15d3792d0a07",
   "metadata": {},
   "source": [
    "***\n",
    "### Compute the weighted MCC:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "768a0b70-b2d3-4fef-b4ab-a90656ac957c",
   "metadata": {},
   "outputs": [],
   "source": [
    "rsync -avzhe ssh \\\n",
    "conchae@garnatxa.srv.cpd:/home/conchae/prediction_depolymerase_tropism/prophage_prediction/depolymerase_decipher/ficheros_28032023/Seqbased_model/metric_files \\\n",
    "/media/concha-eloko/Linux/PPT_clean/ficheros_28032023/review_work/SeqBased_model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dd02ee6a-4764-4877-8824-50300ea3e8ca",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_142516/2213569197.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  metric_eval_df[\"c_value\"] = metric_eval_df[\"file_name\"].astype(str).apply(lambda x: x.split(\"_\")[0])\n",
      "/tmp/ipykernel_142516/2213569197.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  metric_eval_df[\"c_value\"] = metric_eval_df[\"file_name\"].astype(str).apply(lambda x: x.split(\"_\")[0])\n",
      "/tmp/ipykernel_142516/2213569197.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  metric_eval_df[\"c_value\"] = metric_eval_df[\"file_name\"].astype(str).apply(lambda x: x.split(\"_\")[0])\n"
     ]
    }
   ],
   "source": [
    "path_metrics = \"/media/concha-eloko/Linux/PPT_clean/ficheros_28032023/review_work/SeqBased_model/metric_files\"\n",
    "\n",
    "threshold = 5\n",
    "names_metric_col = [\"KL_type\", \"Count\", \"file_name\",\"mean_mcc\"]\n",
    "final_weighted_dico = {}\n",
    "\n",
    "for file in os.listdir(path_metrics):\n",
    "    metric_df = pd.read_csv(f\"{path_metrics}/{file}\", sep = \"\\t\", names = names_metric_col)\n",
    "    metric_eval_df = metric_df[metric_df[\"Count\"] > threshold]\n",
    "    metric_eval_df[\"c_value\"] = metric_eval_df[\"file_name\"].astype(str).apply(lambda x: x.split(\"_\")[0])\n",
    "    weighted_mcc_dico = {}\n",
    "    for cluster in metric_eval_df[\"c_value\"].unique().tolist() :\n",
    "        mcc_sum = 0\n",
    "        cl_df = metric_eval_df[metric_eval_df[\"c_value\"] == cluster]\n",
    "        for _,row in cl_df.iterrows() : \n",
    "            mcc_sum = mcc_sum + row[\"mean_mcc\"] * row[\"Count\"]\n",
    "        weighted_mcc = mcc_sum / (sum(cl_df[\"Count\"]))\n",
    "        weighted_mcc_dico[cluster] = weighted_mcc\n",
    "    final_weighted_dico[file] = weighted_mcc_dico\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a3421131-3b7b-493c-9eae-7c1608f2073d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'SEQ_based.LogReg__UF.prophages_metrics.tsv': {'0.85': 0.3151602636210511,\n",
       "  '0.9': 0.32933361394227706,\n",
       "  '0.8': 0.34091186979267774,\n",
       "  '0.7': 0.36446002765094077,\n",
       "  '0.95': 0.27893023121060845,\n",
       "  '0.75': 0.3463067872443405,\n",
       "  '0.65': 0.36193177410601585,\n",
       "  '0.975': 0.25498957852463594},\n",
       " 'SEQ_based.LogReg.prophages_metrics.tsv': {'0.85': 0.3722464784487348,\n",
       "  '0.9': 0.33694270698415413,\n",
       "  '0.8': 0.3659430012749742,\n",
       "  '0.7': 0.36964008602380943,\n",
       "  '0.95': 0.3319429903096709,\n",
       "  '0.75': 0.374760037337778,\n",
       "  '0.65': 0.39023597272237615,\n",
       "  '0.975': 0.27913217655865474},\n",
       " 'SEQ_based.RF.prophages_metrics.tsv': {'0.95': 0.7505887697037068,\n",
       "  '0.9': 0.7665851018307361,\n",
       "  '0.85': 0.7677152879518742,\n",
       "  '0.75': 0.7576805724196833,\n",
       "  '0.975': 0.7326524783190056,\n",
       "  '0.8': 0.7651531836408012,\n",
       "  '0.7': 0.7564513341443188,\n",
       "  '0.65': 0.7666988914668954},\n",
       " 'SEQ_based.RF__UF.prophages_metrics.tsv': {'0.95': 0.3093359009354269,\n",
       "  '0.9': 0.3353644615409259,\n",
       "  '0.85': 0.35113786424314536,\n",
       "  '0.75': 0.34352863293229235,\n",
       "  '0.975': 0.2615872360477367,\n",
       "  '0.8': 0.3427715092677617,\n",
       "  '0.7': 0.3590017290690274,\n",
       "  '0.65': 0.3669266262836219}}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_weighted_dico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd418cc8-d317-4ff8-b567-91bab1d59208",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEQ_based.LogReg__UF.prophages_metrics.tsv : '0.7': 0.36446002765094077\n",
    "SEQ_based.LogReg.prophages_metrics.tsv : '0.65': 0.39023597272237615 \n",
    "\n",
    "SEQ_based.RF.prophages_metrics.tsv : '0.85': 0.7677152879518742\n",
    "SEQ_based.RF__UF.prophages_metrics.tsv : '0.65': 0.3669266262836219"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:torch_geometric]",
   "language": "python",
   "name": "conda-env-torch_geometric-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
