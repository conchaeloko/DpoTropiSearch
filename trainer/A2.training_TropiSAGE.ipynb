{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de7fe21f-3162-463c-8623-54eae001e7b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import random\n",
    "import warnings\n",
    "from collections import Counter\n",
    "from itertools import product\n",
    "from multiprocessing.pool import ThreadPool\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from sklearn.metrics import (accuracy_score, f1_score, matthews_corrcoef,\n",
    "                             precision_score, recall_score, roc_auc_score)\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder, label_binarize\n",
    "from torch import nn\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from torch_geometric.data import DataLoader, HeteroData\n",
    "from torch_geometric.loader import LinkNeighborLoader\n",
    "from torch_geometric.nn import SAGEConv, HeteroConv, to_hetero\n",
    "from torch_geometric.utils import negative_sampling\n",
    "from tqdm import tqdm\n",
    "\n",
    "import TropiGAT_graph\n",
    "import TropiGAT_models\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Constants\n",
    "# **************************************************\n",
    "ultrafiltration = False\n",
    "# **************************************************\n",
    "\n",
    "PATH_WORK = \"/home/conchae/prediction_depolymerase_tropism/prophage_prediction/depolymerase_decipher/ficheros_28032023\"\n",
    "DATE = \"27_11_2024\"\n",
    "if ultrafiltration == False :\n",
    "    ENSEMBLE_PATH = f\"{PATH_WORK}/train_nn/TropiSAGE_ensemble_{DATE}\"\n",
    "    ENSEMBLE_PATH_log = f\"{PATH_WORK}/train_nn/TropiSAGE_ensemble_{DATE}_log\"\n",
    "    OPTUNA_PATH = f\"{PATH_WORK}/train_nn/ensemble_20112024_log_optimized_SAGE\"\n",
    "else :\n",
    "    ENSEMBLE_PATH = f\"{PATH_WORK}/train_nn/TropiSAGE_ensemble_ultraF_{DATE}\"\n",
    "    ENSEMBLE_PATH_log = f\"{PATH_WORK}/train_nn/TropiSAGE_ensemble_ultraF_{DATE}_log\"\n",
    "    OPTUNA_PATH = f\"{PATH_WORK}/train_nn/ensemble_20112024_log_optimized_SAGE_ultraF\"\n",
    "\n",
    "os.makedirs(ENSEMBLE_PATH, exist_ok=True)\n",
    "os.makedirs(ENSEMBLE_PATH_log, exist_ok=True)\n",
    "\n",
    "DICO_OPTUNA = {}    \n",
    "for file in os.listdir(OPTUNA_PATH):\n",
    "    kl_type = file.split(\"_\")[0]\n",
    "    best_parameters = json.load(open(f\"{OPTUNA_PATH}/{file}\").read())\n",
    "    DICO_OPTUNA[kl_type] = best_parameters\n",
    "    \n",
    "\n",
    "def load_and_preprocess_data():\n",
    "    \"\"\"Load and preprocess the prophage data.\"\"\"\n",
    "    df_info = pd.read_csv(f\"{PATH_WORK}/train_nn/TropiGATv2.final_df_v2.tsv\", sep=\"\\t\", header=0)\n",
    "    df_info = df_info.drop_duplicates(subset=[\"Protein_name\"])\n",
    "    \n",
    "    df_prophages = df_info.drop_duplicates(subset=[\"Phage\"], keep=\"first\")\n",
    "    dico_prophage_info = {row[\"Phage\"]: {\"prophage_strain\": row[\"prophage_id\"], \"ancestor\": row[\"Infected_ancestor\"]} \n",
    "                          for _, row in df_prophages.iterrows()}\n",
    "    \n",
    "    return df_info, dico_prophage_info\n",
    "\n",
    "def filter_prophages(df_info, dico_prophage_info):\n",
    "    \"\"\"Filter prophages to remove duplicates and ensure diversity.\"\"\"\n",
    "    def get_filtered_prophages(prophage):\n",
    "        combinations = []\n",
    "        to_exclude = set()\n",
    "        to_keep = set()\n",
    "        to_keep.add(prophage)\n",
    "        df_prophage_group = df_info[\n",
    "            (df_info[\"prophage_id\"] == dico_prophage_info[prophage][\"prophage_strain\"]) & \n",
    "            (df_info[\"Infected_ancestor\"] == dico_prophage_info[prophage][\"ancestor\"])\n",
    "        ]\n",
    "        if len(df_prophage_group) == 1:\n",
    "            return df_prophage_group, to_exclude, to_keep\n",
    "        \n",
    "        depo_set = set(df_prophage_group[df_prophage_group[\"Phage\"] == prophage][\"domain_seq\"].values)\n",
    "        for prophage_tmp in df_prophage_group[\"Phage\"].unique():\n",
    "            if prophage_tmp != prophage:\n",
    "                tmp_depo_set = set(df_prophage_group[df_prophage_group[\"Phage\"] == prophage_tmp][\"domain_seq\"].values)\n",
    "                if depo_set == tmp_depo_set:\n",
    "                    to_exclude.add(prophage_tmp)\n",
    "                elif tmp_depo_set not in combinations:\n",
    "                    to_keep.add(prophage_tmp)\n",
    "                    combinations.append(tmp_depo_set)\n",
    "                else:\n",
    "                    to_exclude.add(prophage_tmp)\n",
    "        return df_prophage_group, to_exclude, to_keep\n",
    "\n",
    "    good_prophages = set()\n",
    "    excluded_prophages = set()\n",
    "\n",
    "    for prophage in tqdm(dico_prophage_info.keys()):\n",
    "        if prophage not in excluded_prophages and prophage not in good_prophages:\n",
    "            _, excluded_members, kept_members = get_filtered_prophages(prophage)\n",
    "            good_prophages.update(kept_members)\n",
    "            excluded_prophages.update(excluded_members)\n",
    "\n",
    "    df_info_filtered = df_info[df_info[\"Phage\"].isin(good_prophages)]\n",
    "    df_info_final = df_info_filtered[~df_info_filtered[\"KL_type_LCA\"].str.contains(\"\\\\|\")]\n",
    "\n",
    "    return df_info_final\n",
    "\n",
    "\n",
    "def ultrafilter_prophages(df_info):\n",
    "    \"\"\"Perform ultra-filtration to remove duplicate prophages within KL types.\"\"\"\n",
    "    duplicate_prophage = []\n",
    "    dico_kltype_duplica = {}\n",
    "\n",
    "    for kltype in df_info[\"KL_type_LCA\"].unique():\n",
    "        df_kl = df_info[df_info[\"KL_type_LCA\"] == kltype][[\"Phage\", \"Protein_name\", \"KL_type_LCA\", \"Infected_ancestor\", \"index\", \"seq\", \"domain_seq\"]]\n",
    "        prophages_tmp_list = df_kl[\"Phage\"].unique().tolist()\n",
    "        set_sets_depo = []\n",
    "        duplicated = {}  \n",
    "        for prophage_tmp in prophages_tmp_list: \n",
    "            set_depo = frozenset(df_kl[df_kl[\"Phage\"] == prophage_tmp][\"domain_seq\"].values)\n",
    "            for past_set in set_sets_depo:\n",
    "                if past_set == set_depo:\n",
    "                    duplicated[past_set] = duplicated.get(past_set, 0) + 1\n",
    "                    duplicate_prophage.append(prophage_tmp)\n",
    "                    break\n",
    "            else:\n",
    "                set_sets_depo.append(set_depo)\n",
    "                duplicated[set_depo] = 1\n",
    "        dico_kltype_duplica[kltype] = duplicated\n",
    "\n",
    "    df_info_ultrafiltered = df_info[~df_info[\"Phage\"].isin(duplicate_prophage)]\n",
    "    return df_info_ultrafiltered\n",
    "\n",
    "\n",
    "def prepare_kltypes(df_info):\n",
    "    \"\"\"Prepare KL types for training.\"\"\"\n",
    "    df_prophages = df_info.drop_duplicates(subset=[\"Phage\"])\n",
    "    dico_prophage_count = dict(Counter(df_prophages[\"KL_type_LCA\"]))\n",
    "    kltypes = [kltype for kltype, count in dico_prophage_count.items() if count >= 10]\n",
    "    return kltypes, dico_prophage_count\n",
    "\n",
    "\n",
    "class TropiGAT_small_sage_module(torch.nn.Module):\n",
    "    def __init__(self,hidden_channels, edge_type = (\"B2\", \"expressed\", \"B1\") ,dropout = 0.2, conv = SAGEConv):\n",
    "        super().__init__()\n",
    "        # GATv2 module :\n",
    "        self.conv = conv((-1,-1), hidden_channels)\n",
    "        self.hetero_conv = HeteroConv({edge_type: self.conv})\n",
    "        # FNN layers : \n",
    "        self.linear_layers = nn.Sequential(nn.Linear(hidden_channels, 1280),\n",
    "                                           nn.BatchNorm1d(1280),\n",
    "                                           nn.LeakyReLU(),\n",
    "                                           torch.nn.Dropout(dropout),\n",
    "                                           nn.Linear(1280, 480),\n",
    "                                           nn.BatchNorm1d(480),\n",
    "                                           nn.LeakyReLU(),\n",
    "                                           torch.nn.Dropout(dropout),\n",
    "                                           nn.Linear(480 , 1))\n",
    "        \n",
    "    def forward(self, graph_data):\n",
    "        x_B1_dict  = self.hetero_conv(graph_data.x_dict, graph_data.edge_index_dict)\n",
    "        x = self.linear_layers(x_B1_dict[\"B1\"])\n",
    "        return x.view(-1)\n",
    "    \n",
    "\n",
    "def train_graph(kl_type, graph_baseline, dico_prophage_kltype_associated, df_info, dico_prophage_count):\n",
    "    \"\"\"Train the graph neural network for a specific KL type.\"\"\"\n",
    "    for seed in range(1, 6):\n",
    "        if os.path.isfile(f\"{ENSEMBLE_PATH_log}/{kl_type}__{seed}__node_classification.{DATE}.log\") == False :\n",
    "            log_file = f\"{ENSEMBLE_PATH_log}/{kl_type}__{seed}__node_classification.{DATE}.log\"\n",
    "            with open(log_file, \"w\") as log_outfile:\n",
    "                try:\n",
    "                    n_prophage = dico_prophage_count[kl_type]\n",
    "                    graph_data_kltype = TropiGAT_graph.build_graph_masking_v2(\n",
    "                        graph_baseline, dico_prophage_kltype_associated, df_info, \n",
    "                        kl_type, 5, 0.7, 0.2, 0.1, seed=seed\n",
    "                    )\n",
    "                    model = TropiGAT_small_sage_module(\n",
    "                        hidden_channels = 1280, \n",
    "                        dropout = DICO_OPTUNA[kl_type][\"dropout\"], \n",
    "                    )\n",
    "\n",
    "                    model(graph_data_kltype)\n",
    "\n",
    "                    optimizer = torch.optim.AdamW(\n",
    "                        model.parameters(), \n",
    "                        lr = DICO_OPTUNA[kl_type][\"lr\"], \n",
    "                        weight_decay = DICO_OPTUNA[kl_type][\"weight_decay\"]\n",
    "                    )\n",
    "                    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', patience=5, min_lr=1e-6)\n",
    "                    criterion = torch.nn.BCEWithLogitsLoss()\n",
    "                    early_stopping = TropiGAT_models.EarlyStopping(\n",
    "                        patience=100, \n",
    "                        verbose=True, \n",
    "                        path=f\"{ENSEMBLE_PATH}/{kl_type}__{seed}.TropiSAGE.{DATE}.pt\", \n",
    "                        metric='MCC'\n",
    "                    )\n",
    "\n",
    "                    for epoch in range(500):\n",
    "                        train_loss = TropiGAT_models.train(model, graph_data_kltype, optimizer, criterion)\n",
    "                        if epoch % 5 == 0:\n",
    "                            test_loss, metrics = TropiGAT_models.evaluate(\n",
    "                                model, graph_data_kltype, criterion, graph_data_kltype[\"B1\"].test_mask\n",
    "                            )\n",
    "                            log_outfile.write(f'Epoch: {epoch}\\tTrain Loss: {train_loss:.4f}\\t'\n",
    "                                              f'Test Loss: {test_loss:.4f}\\tMCC: {metrics[3]:.4f}\\t'\n",
    "                                              f'AUC: {metrics[5]:.4f}\\tAccuracy: {metrics[4]:.4f}\\n')\n",
    "                            scheduler.step(test_loss)\n",
    "                            early_stopping(metrics[3], model, epoch)\n",
    "                            if early_stopping.early_stop:\n",
    "                                log_outfile.write(f\"Early stopping at epoch {epoch}\\n\")\n",
    "                                break\n",
    "                    else:\n",
    "                        torch.save(model, f\"{ENSEMBLE_PATH}/{kl_type}__{seed}.TropiSAGE.{DATE}.pt\")\n",
    "\n",
    "                    # Final evaluation\n",
    "                    model_final = TropiGAT_small_sage_module(\n",
    "                        hidden_channels = 1280, \n",
    "                        dropout = DICO_OPTUNA[kl_type][\"dropout\"], \n",
    "                    )\n",
    "                    model_final.load_state_dict(torch.load(f\"{ENSEMBLE_PATH}/{kl_type}__{seed}.TropiSAGE.{DATE}.pt\"))\n",
    "                    eval_loss, metrics = TropiGAT_models.evaluate(\n",
    "                        model_final, graph_data_kltype, criterion, graph_data_kltype[\"B1\"].eval_mask\n",
    "                    )\n",
    "\n",
    "                    with open(f\"{ENSEMBLE_PATH_log}/Metric_Report.{DATE}.tsv\", \"a+\") as metric_outfile:\n",
    "                        metric_outfile.write(f\"{kl_type}__{seed}\\t{n_prophage}\\t\"\n",
    "                                             f\"{metrics[0]:.4f}\\t{metrics[1]:.4f}\\t{metrics[2]:.4f}\\t\"\n",
    "                                             f\"{metrics[3]:.4f}\\t{metrics[4]:.4f}\\t{metrics[5]:.4f}\\n\")\n",
    "\n",
    "                    log_outfile.write(f\"Final evaluation:\\n\"\n",
    "                                      f\"F1 Score: {metrics[0]:.4f}, Precision: {metrics[1]:.4f}, \"\n",
    "                                      f\"Recall: {metrics[2]:.4f}, MCC: {metrics[3]:.4f}, \"\n",
    "                                      f\"Accuracy: {metrics[4]:.4f}, AUC: {metrics[5]:.4f}\")\n",
    "\n",
    "                except Exception as e:\n",
    "                    log_outfile.write(f\"Error occurred: {str(e)}\")\n",
    "                    with open(f\"{ENSEMBLE_PATH_log}/Metric_Report.{DATE}.tsv\", \"a+\") as metric_outfile:\n",
    "                        metric_outfile.write(f\"{kl_type}__{seed}\\t{n_prophage}\\t***Error***\\n\")\n",
    "\n",
    "def main():\n",
    "    \"\"\"Main function to orchestrate the TropiSAGE workflow.\"\"\"\n",
    "    df_info, dico_prophage_info = load_and_preprocess_data()\n",
    "    if ultrafiltration == True :\n",
    "        df_info_final = ultrafilter_prophages(filter_prophages(df_info, dico_prophage_info))\n",
    "    else :\n",
    "        df_info_final = filter_prophages(df_info, dico_prophage_info)\n",
    "    \n",
    "    kltypes, dico_prophage_count = prepare_kltypes(df_info_filtered)\n",
    "    graph_baseline, dico_prophage_kltype_associated = TropiGAT_graph.build_graph_baseline(df_info_final)\n",
    "    \n",
    "    with ThreadPool(5) as p:\n",
    "        p.starmap(train_graph, [(kl_type, graph_baseline, dico_prophage_kltype_associated, df_info_final, dico_prophage_count) for kl_type in kltypes])\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e03cc530-b737-43a8-b936-ecceb36a08c0",
   "metadata": {},
   "source": [
    "***\n",
    "### Move the best version of the model to local: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cba286b8-7e1a-4da2-ac49-b36a82199f25",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd19134d-f3d3-45b8-8273-07af33119b99",
   "metadata": {},
   "source": [
    "> regular filtration: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "13688e4e-6e2d-4b04-9583-d6cd1bb0a7ed",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'KL1': '4', 'KL2': '4', 'KL3': '5', 'KL4': '5', 'KL5': '4', 'KL6': '2', 'KL7': '1', 'KL8': '4', 'KL9': '5', 'KL10': '3', 'KL12': '1', 'KL13': '1', 'KL14': '1', 'KL15': '1', 'KL16': '5', 'KL17': '2', 'KL18': '3', 'KL19': '4', 'KL20': '3', 'KL21': '1', 'KL22': '5', 'KL23': '5', 'KL24': '4', 'KL25': '5', 'KL26': '4', 'KL27': '4', 'KL28': '3', 'KL29': '5', 'KL30': '2', 'KL31': '5', 'KL34': '5', 'KL35': '2', 'KL36': '4', 'KL38': '2', 'KL39': '5', 'KL41': '3', 'KL43': '4', 'KL45': '4', 'KL46': '2', 'KL47': '5', 'KL48': '5', 'KL51': '2', 'KL52': '2', 'KL53': '2', 'KL54': '1', 'KL55': '5', 'KL56': '3', 'KL57': '2', 'KL60': '4', 'KL61': '3', 'KL62': '2', 'KL63': '3', 'KL64': '2', 'KL67': '4', 'KL70': '2', 'KL71': '3', 'KL74': '2', 'KL81': '1', 'KL102': '5', 'KL103': '3', 'KL105': '5', 'KL106': '3', 'KL107': '1', 'KL108': '3', 'KL109': '3', 'KL110': '1', 'KL111': '4', 'KL112': '4', 'KL114': '5', 'KL116': '1', 'KL117': '5', 'KL118': '1', 'KL122': '4', 'KL123': '2', 'KL124': '5', 'KL125': '1', 'KL127': '4', 'KL128': '1', 'KL136': '3', 'KL139': '1', 'KL140': '5', 'KL142': '1', 'KL143': '5', 'KL145': '3', 'KL149': '4', 'KL151': '5', 'KL152': '1', 'KL153': '4', 'KL155': '2', 'KL157': '4', 'KL166': '3', 'KL169': '3'}\n"
     ]
    }
   ],
   "source": [
    "average_metric_df = pd.read_csv(f\"/media/concha-eloko/Linux/PPT_clean/ficheros_28032023/Metric_Report.review.SAGE.F.tsv\", sep = \"\\t\", index_col = False, header = 0)\n",
    "\n",
    "model_version = {kltype.split(\"_\")[0] : kltype.split(\"_\")[-1] for kltype in average_metric_df[\"model_version\"]}\n",
    "print(model_version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3afa52ef-9488-432c-a6bb-8e104a37fa02",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "\n",
    "path_work = f\"/home/conchae/prediction_depolymerase_tropism/prophage_prediction/depolymerase_decipher/ficheros_28032023/train_nn\"\n",
    "path_best_models = f\"{path_work}/best_models\"\n",
    "path_models = f\"{path_work}/TropiSAGE_ensemble_27_11_2024\"\n",
    "\n",
    "index = \"TropiSAGE.27_11_2024.pt\"\n",
    "\n",
    "model_version = {'KL1': '4', 'KL2': '4', 'KL3': '5', 'KL4': '5', 'KL5': '4', 'KL6': '2', 'KL7': '1', 'KL8': '4', 'KL9': '5', 'KL10': '3', 'KL12': '1', 'KL13': '1', 'KL14': '1', 'KL15': '1', 'KL16': '5', 'KL17': '2', 'KL18': '3', 'KL19': '4', 'KL20': '3', 'KL21': '1', 'KL22': '5', 'KL23': '5', 'KL24': '4', 'KL25': '5', 'KL26': '4', 'KL27': '4', 'KL28': '3', 'KL29': '5', 'KL30': '2', 'KL31': '5', 'KL34': '5', 'KL35': '2', 'KL36': '4', 'KL38': '2', 'KL39': '5', 'KL41': '3', 'KL43': '4', 'KL45': '4', 'KL46': '2', 'KL47': '5', 'KL48': '5', 'KL51': '2', 'KL52': '2', 'KL53': '2', 'KL54': '1', 'KL55': '5', 'KL56': '3', 'KL57': '2', 'KL60': '4', 'KL61': '3', 'KL62': '2', 'KL63': '3', 'KL64': '2', 'KL67': '4', 'KL70': '2', 'KL71': '3', 'KL74': '2', 'KL81': '1', 'KL102': '5', 'KL103': '3', 'KL105': '5', 'KL106': '3', 'KL107': '1', 'KL108': '3', 'KL109': '3', 'KL110': '1', 'KL111': '4', 'KL112': '4', 'KL114': '5', 'KL116': '1', 'KL117': '5', 'KL118': '1', 'KL122': '4', 'KL123': '2', 'KL124': '5', 'KL125': '1', 'KL127': '4', 'KL128': '1', 'KL136': '3', 'KL139': '1', 'KL140': '5', 'KL142': '1', 'KL143': '5', 'KL145': '3', 'KL149': '4', 'KL151': '5', 'KL152': '1', 'KL153': '4', 'KL155': '2', 'KL157': '4', 'KL166': '3', 'KL169': '3'}\n",
    "for kltype, version in model_version.items(): \n",
    "    os.system(f\"cp {path_models}/{kltype}__{version}.{index} {path_best_models}/best_models_TropiSAGE\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3966e20-ea77-4895-a40e-2ef674f18f12",
   "metadata": {},
   "source": [
    "> Ultrafiltration : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "46980cda-39fd-49da-8a86-65fdd39d22ba",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'KL1': '3', 'KL2': '3', 'KL3': '5', 'KL4': '3', 'KL5': '2', 'KL6': '5', 'KL7': '2', 'KL8': '2', 'KL9': '4', 'KL10': '3', 'KL12': '4', 'KL13': '1', 'KL14': '3', 'KL15': '3', 'KL16': '5', 'KL17': '5', 'KL18': '1', 'KL19': '4', 'KL20': '3', 'KL21': '3', 'KL22': '4', 'KL23': '2', 'KL24': '5', 'KL25': '3', 'KL26': '1', 'KL27': '5', 'KL28': '5', 'KL29': '2', 'KL30': '5', 'KL31': '5', 'KL34': '5', 'KL35': '2', 'KL36': '1', 'KL38': '4', 'KL39': '3', 'KL43': '1', 'KL45': '4', 'KL46': '4', 'KL47': '1', 'KL48': '3', 'KL51': '2', 'KL52': '2', 'KL53': '4', 'KL55': '1', 'KL56': '2', 'KL57': '3', 'KL60': '3', 'KL62': '2', 'KL63': '3', 'KL64': '3', 'KL67': '4', 'KL70': '5', 'KL71': '1', 'KL74': '1', 'KL81': '2', 'KL102': '5', 'KL103': '5', 'KL105': '2', 'KL106': '3', 'KL107': '1', 'KL108': '1', 'KL109': '3', 'KL110': '5', 'KL111': '3', 'KL112': '2', 'KL114': '1', 'KL116': '1', 'KL117': '1', 'KL118': '4', 'KL122': '1', 'KL123': '1', 'KL124': '2', 'KL125': '3', 'KL127': '1', 'KL128': '3', 'KL136': '3', 'KL140': '5', 'KL142': '1', 'KL145': '1', 'KL149': '3', 'KL151': '1', 'KL153': '4', 'KL155': '5', 'KL157': '3', 'KL169': '5'}\n"
     ]
    }
   ],
   "source": [
    "average_metric_df = pd.read_csv(f\"/media/concha-eloko/Linux/PPT_clean/ficheros_28032023/Metric_Report.review.SAGE.UF.tsv\", sep = \"\\t\", index_col = False, header = 0)\n",
    "\n",
    "model_version = {kltype.split(\"_\")[0] : kltype.split(\"_\")[-1] for kltype in average_metric_df[\"model_version\"]}\n",
    "print(model_version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f70a869b-cca2-41c3-9be5-f7b81da10c35",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "\n",
    "path_work = f\"/home/conchae/prediction_depolymerase_tropism/prophage_prediction/depolymerase_decipher/ficheros_28032023/train_nn\"\n",
    "path_best_models = f\"{path_work}/best_models\"\n",
    "path_models = f\"{path_work}/TropiSAGE_ensemble_ultraF_27_11_2024\"\n",
    "\n",
    "index = \"TropiSAGE.27_11_2024.pt\"\n",
    "\n",
    "model_version = {'KL1': '3', 'KL2': '3', 'KL3': '5', 'KL4': '3', 'KL5': '2', 'KL6': '5', 'KL7': '2', 'KL8': '2', 'KL9': '4', 'KL10': '3', 'KL12': '4', 'KL13': '1', 'KL14': '3', 'KL15': '3', 'KL16': '5', 'KL17': '5', 'KL18': '1', 'KL19': '4', 'KL20': '3', 'KL21': '3', 'KL22': '4', 'KL23': '2', 'KL24': '5', 'KL25': '3', 'KL26': '1', 'KL27': '5', 'KL28': '5', 'KL29': '2', 'KL30': '5', 'KL31': '5', 'KL34': '5', 'KL35': '2', 'KL36': '1', 'KL38': '4', 'KL39': '3', 'KL43': '1', 'KL45': '4', 'KL46': '4', 'KL47': '1', 'KL48': '3', 'KL51': '2', 'KL52': '2', 'KL53': '4', 'KL55': '1', 'KL56': '2', 'KL57': '3', 'KL60': '3', 'KL62': '2', 'KL63': '3', 'KL64': '3', 'KL67': '4', 'KL70': '5', 'KL71': '1', 'KL74': '1', 'KL81': '2', 'KL102': '5', 'KL103': '5', 'KL105': '2', 'KL106': '3', 'KL107': '1', 'KL108': '1', 'KL109': '3', 'KL110': '5', 'KL111': '3', 'KL112': '2', 'KL114': '1', 'KL116': '1', 'KL117': '1', 'KL118': '4', 'KL122': '1', 'KL123': '1', 'KL124': '2', 'KL125': '3', 'KL127': '1', 'KL128': '3', 'KL136': '3', 'KL140': '5', 'KL142': '1', 'KL145': '1', 'KL149': '3', 'KL151': '1', 'KL153': '4', 'KL155': '5', 'KL157': '3', 'KL169': '5'}\n",
    "\n",
    "for kltype, version in model_version.items(): \n",
    "    os.system(f\"cp {path_models}/{kltype}__{version}.{index} {path_best_models}/best_models_TropiSAGE_UF \")\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c044f7e2-caaf-4446-9188-ff7baa9826ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "rsync -avzhe ssh \\\n",
    "conchae@garnatxa.srv.cpd:/home/conchae/prediction_depolymerase_tropism/prophage_prediction/depolymerase_decipher/ficheros_28032023/train_nn/best_models \\\n",
    "/media/concha-eloko/Linux/PPT_clean/reviewed_models\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:torch_geometric]",
   "language": "python",
   "name": "conda-env-torch_geometric-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
