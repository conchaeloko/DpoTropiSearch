{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d6c8fc3-55fd-4a14-8fe8-0a63a7abd8fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import random\n",
    "import warnings\n",
    "from collections import Counter\n",
    "from itertools import product\n",
    "from multiprocessing.pool import ThreadPool\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from sklearn.metrics import (accuracy_score, f1_score, matthews_corrcoef,\n",
    "                             precision_score, recall_score, roc_auc_score)\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder, label_binarize\n",
    "from torch import nn\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from torch_geometric.data import DataLoader, HeteroData\n",
    "from torch_geometric.loader import LinkNeighborLoader\n",
    "from torch_geometric.nn import GATv2Conv, HeteroConv, to_hetero\n",
    "from torch_geometric.utils import negative_sampling\n",
    "from tqdm import tqdm\n",
    "\n",
    "import TropiGAT_graph\n",
    "import TropiGAT_models\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Constants\n",
    "# **************************************************\n",
    "ultrafiltration = False\n",
    "# **************************************************\n",
    "\n",
    "PATH_WORK = \"/home/conchae/prediction_depolymerase_tropism/prophage_prediction/depolymerase_decipher/ficheros_28032023\"\n",
    "DATE = \"27_11_2024\"\n",
    "\n",
    "if ultrafiltration == False :\n",
    "    ENSEMBLE_PATH = f\"{PATH_WORK}/train_nn/TropiGAT_ensemble_{DATE}\"\n",
    "    ENSEMBLE_PATH_log = f\"{PATH_WORK}/train_nn/TropiGAT_ensemble_{DATE}_log\"\n",
    "    OPTUNA_PATH = f\"{PATH_WORK}/train_nn/ensemble_20112024_log_optimized_TropiGAT\"\n",
    "else :\n",
    "    ENSEMBLE_PATH = f\"{PATH_WORK}/train_nn/TropiGAT_ensemble_ultraF_{DATE}\"\n",
    "    ENSEMBLE_PATH_log = f\"{PATH_WORK}/train_nn/TropiGAT_ensemble_ultraF_{DATE}_log\"\n",
    "    OPTUNA_PATH = f\"{PATH_WORK}/train_nn/ensemble_20112024_log_optimized_TropiGAT_ultraF\"\n",
    "        \n",
    "os.makedirs(ENSEMBLE_PATH, exist_ok=True)\n",
    "os.makedirs(ENSEMBLE_PATH_log, exist_ok=True)\n",
    "\n",
    "\n",
    "DICO_OPTUNA = {}    \n",
    "for file in os.listdir(OPTUNA_PATH):\n",
    "    kl_type = file.split(\"_\")[0]\n",
    "    best_parameters = json.load(open(f\"{OPTUNA_PATH}/{file}\").read())\n",
    "    DICO_OPTUNA[kl_type] = best_parameters\n",
    "    \n",
    "\n",
    "def load_and_preprocess_data():\n",
    "    \"\"\"Load and preprocess the prophage data.\"\"\"\n",
    "    df_info = pd.read_csv(f\"{PATH_WORK}/train_nn/TropiGATv2.final_df_v2.tsv\", sep=\"\\t\", header=0)\n",
    "    df_info = df_info.drop_duplicates(subset=[\"Protein_name\"])\n",
    "    \n",
    "    df_prophages = df_info.drop_duplicates(subset=[\"Phage\"], keep=\"first\")\n",
    "    dico_prophage_info = {row[\"Phage\"]: {\"prophage_strain\": row[\"prophage_id\"], \"ancestor\": row[\"Infected_ancestor\"]} \n",
    "                          for _, row in df_prophages.iterrows()}\n",
    "    \n",
    "    return df_info, dico_prophage_info\n",
    "\n",
    "def filter_prophages(df_info, dico_prophage_info):\n",
    "    \"\"\"Filter prophages to remove duplicates and ensure diversity.\"\"\"\n",
    "    def get_filtered_prophages(prophage):\n",
    "        combinations = []\n",
    "        to_exclude = set()\n",
    "        to_keep = set()\n",
    "        to_keep.add(prophage)\n",
    "        df_prophage_group = df_info[\n",
    "            (df_info[\"prophage_id\"] == dico_prophage_info[prophage][\"prophage_strain\"]) & \n",
    "            (df_info[\"Infected_ancestor\"] == dico_prophage_info[prophage][\"ancestor\"])\n",
    "        ]\n",
    "        if len(df_prophage_group) == 1:\n",
    "            return df_prophage_group, to_exclude, to_keep\n",
    "        \n",
    "        depo_set = set(df_prophage_group[df_prophage_group[\"Phage\"] == prophage][\"domain_seq\"].values)\n",
    "        for prophage_tmp in df_prophage_group[\"Phage\"].unique():\n",
    "            if prophage_tmp != prophage:\n",
    "                tmp_depo_set = set(df_prophage_group[df_prophage_group[\"Phage\"] == prophage_tmp][\"domain_seq\"].values)\n",
    "                if depo_set == tmp_depo_set:\n",
    "                    to_exclude.add(prophage_tmp)\n",
    "                elif tmp_depo_set not in combinations:\n",
    "                    to_keep.add(prophage_tmp)\n",
    "                    combinations.append(tmp_depo_set)\n",
    "                else:\n",
    "                    to_exclude.add(prophage_tmp)\n",
    "        return df_prophage_group, to_exclude, to_keep\n",
    "\n",
    "    good_prophages = set()\n",
    "    excluded_prophages = set()\n",
    "\n",
    "    for prophage in tqdm(dico_prophage_info.keys()):\n",
    "        if prophage not in excluded_prophages and prophage not in good_prophages:\n",
    "            _, excluded_members, kept_members = get_filtered_prophages(prophage)\n",
    "            good_prophages.update(kept_members)\n",
    "            excluded_prophages.update(excluded_members)\n",
    "\n",
    "    df_info_filtered = df_info[df_info[\"Phage\"].isin(good_prophages)]\n",
    "    df_info_final = df_info_filtered[~df_info_filtered[\"KL_type_LCA\"].str.contains(\"\\\\|\")]\n",
    "\n",
    "    return df_info_final\n",
    "\n",
    "\n",
    "def ultrafilter_prophages(df_info):\n",
    "    \"\"\"Perform ultra-filtration to remove duplicate prophages within KL types.\"\"\"\n",
    "    duplicate_prophage = []\n",
    "    dico_kltype_duplica = {}\n",
    "\n",
    "    for kltype in df_info[\"KL_type_LCA\"].unique():\n",
    "        df_kl = df_info[df_info[\"KL_type_LCA\"] == kltype][[\"Phage\", \"Protein_name\", \"KL_type_LCA\", \"Infected_ancestor\", \"index\", \"seq\", \"domain_seq\"]]\n",
    "        prophages_tmp_list = df_kl[\"Phage\"].unique().tolist()\n",
    "        set_sets_depo = []\n",
    "        duplicated = {}  \n",
    "        for prophage_tmp in prophages_tmp_list: \n",
    "            set_depo = frozenset(df_kl[df_kl[\"Phage\"] == prophage_tmp][\"domain_seq\"].values)\n",
    "            for past_set in set_sets_depo:\n",
    "                if past_set == set_depo:\n",
    "                    duplicated[past_set] = duplicated.get(past_set, 0) + 1\n",
    "                    duplicate_prophage.append(prophage_tmp)\n",
    "                    break\n",
    "            else:\n",
    "                set_sets_depo.append(set_depo)\n",
    "                duplicated[set_depo] = 1\n",
    "        dico_kltype_duplica[kltype] = duplicated\n",
    "\n",
    "    df_info_ultrafiltered = df_info[~df_info[\"Phage\"].isin(duplicate_prophage)]\n",
    "    return df_info_ultrafiltered\n",
    "\n",
    "\n",
    "def prepare_kltypes(df_info):\n",
    "    \"\"\"Prepare KL types for training.\"\"\"\n",
    "    df_prophages = df_info.drop_duplicates(subset=[\"Phage\"])\n",
    "    dico_prophage_count = dict(Counter(df_prophages[\"KL_type_LCA\"]))\n",
    "    kltypes = [kltype for kltype, count in dico_prophage_count.items() if count >= 10]\n",
    "    return kltypes, dico_prophage_count\n",
    "\n",
    "\n",
    "\n",
    "def train_graph(kl_type, graph_baseline, dico_prophage_kltype_associated, df_info, dico_prophage_count):\n",
    "    \"\"\"Train the graph neural network for a specific KL type.\"\"\"\n",
    "    for seed in range(1, 6):\n",
    "        if os.path.isfile(f\"{ENSEMBLE_PATH_log}/{kl_type}__{seed}__node_classification.{DATE}.log\") == False :\n",
    "            log_file = f\"{ENSEMBLE_PATH_log}/{kl_type}__{seed}__node_classification.{DATE}.log\"\n",
    "            with open(log_file, \"w\") as log_outfile:\n",
    "                try:\n",
    "                    n_prophage = dico_prophage_count[kl_type]\n",
    "                    graph_data_kltype = TropiGAT_graph.build_graph_masking_v2(\n",
    "                        graph_baseline, dico_prophage_kltype_associated, df_info, \n",
    "                        kl_type, 5, 0.7, 0.2, 0.1, seed=seed\n",
    "                    )\n",
    "\n",
    "                    model = TropiGAT_models.TropiGAT_small_module(\n",
    "                        hidden_channels=1280, heads= DICO_OPTUNA[kl_type][\"att_heads\"], dropout = DICO_OPTUNA[kl_type][\"dropout\"]\n",
    "                    )\n",
    "                    model(graph_data_kltype)\n",
    "\n",
    "                    optimizer = torch.optim.AdamW(\n",
    "                        model.parameters(), \n",
    "                        lr=DICO_OPTUNA[kl_type][\"lr\"], \n",
    "                        weight_decay=DICO_OPTUNA[kl_type][\"weight_decay\"]\n",
    "                    )\n",
    "                    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', patience=5, min_lr=1e-6)\n",
    "                    criterion = torch.nn.BCEWithLogitsLoss()\n",
    "                    early_stopping = TropiGAT_models.EarlyStopping(\n",
    "                        patience=100, \n",
    "                        verbose=True, \n",
    "                        path=f\"{ENSEMBLE_PATH}/{kl_type}__{seed}.TropiGATv2.{DATE}.pt\", \n",
    "                        metric='MCC'\n",
    "                    )\n",
    "\n",
    "                    for epoch in range(500):\n",
    "                        train_loss = TropiGAT_models.train(model, graph_data_kltype, optimizer, criterion)\n",
    "                        if epoch % 5 == 0:\n",
    "                            test_loss, metrics = TropiGAT_models.evaluate(\n",
    "                                model, graph_data_kltype, criterion, graph_data_kltype[\"B1\"].test_mask\n",
    "                            )\n",
    "                            log_outfile.write(f'Epoch: {epoch}\\tTrain Loss: {train_loss:.4f}\\t'\n",
    "                                              f'Test Loss: {test_loss:.4f}\\tMCC: {metrics[3]:.4f}\\t'\n",
    "                                              f'AUC: {metrics[5]:.4f}\\tAccuracy: {metrics[4]:.4f}\\n')\n",
    "                            scheduler.step(test_loss)\n",
    "                            early_stopping(metrics[3], model, epoch)\n",
    "                            if early_stopping.early_stop:\n",
    "                                log_outfile.write(f\"Early stopping at epoch {epoch}\\n\")\n",
    "                                break\n",
    "                    else:\n",
    "                        torch.save(model, f\"{ENSEMBLE_PATH}/{kl_type}__{seed}.TropiGATv2.{DATE}.pt\")\n",
    "\n",
    "                    # Final evaluation\n",
    "                    model_final = TropiGAT_models.TropiGAT_small_module(\n",
    "                        hidden_channels=1280, heads = DICO_OPTUNA[kl_type][\"att_heads\"], dropout = DICO_OPTUNA[kl_type][\"dropout\"]\n",
    "                    )\n",
    "                    model_final.load_state_dict(torch.load(f\"{ENSEMBLE_PATH}/{kl_type}__{seed}.TropiGATv2.{DATE}.pt\"))\n",
    "                    eval_loss, metrics = TropiGAT_models.evaluate(\n",
    "                        model_final, graph_data_kltype, criterion, graph_data_kltype[\"B1\"].eval_mask\n",
    "                    )\n",
    "\n",
    "                    with open(f\"{ENSEMBLE_PATH_log}/Metric_Report.{DATE}.tsv\", \"a+\") as metric_outfile:\n",
    "                        metric_outfile.write(f\"{kl_type}__{seed}\\t{n_prophage}\\t\"\n",
    "                                             f\"{metrics[0]:.4f}\\t{metrics[1]:.4f}\\t{metrics[2]:.4f}\\t\"\n",
    "                                             f\"{metrics[3]:.4f}\\t{metrics[4]:.4f}\\t{metrics[5]:.4f}\\n\")\n",
    "\n",
    "                    log_outfile.write(f\"Final evaluation:\\n\"\n",
    "                                      f\"F1 Score: {metrics[0]:.4f}, Precision: {metrics[1]:.4f}, \"\n",
    "                                      f\"Recall: {metrics[2]:.4f}, MCC: {metrics[3]:.4f}, \"\n",
    "                                      f\"Accuracy: {metrics[4]:.4f}, AUC: {metrics[5]:.4f}\")\n",
    "\n",
    "                except Exception as e:\n",
    "                    log_outfile.write(f\"Error occurred: {str(e)}\")\n",
    "                    with open(f\"{ENSEMBLE_PATH_log}/Metric_Report.{DATE}.tsv\", \"a+\") as metric_outfile:\n",
    "                        metric_outfile.write(f\"{kl_type}__{seed}\\t{n_prophage}\\t***Error***\\n\")\n",
    "\n",
    "def main():\n",
    "    \"\"\"Main function to orchestrate the TropiGAT workflow.\"\"\"\n",
    "    df_info, dico_prophage_info = load_and_preprocess_data()\n",
    "    if ultrafiltration == True :\n",
    "        df_info_final = ultrafilter_prophages(filter_prophages(df_info, dico_prophage_info))\n",
    "    else :\n",
    "        df_info_final = filter_prophages(df_info, dico_prophage_info)\n",
    "    \n",
    "    kltypes, dico_prophage_count = prepare_kltypes(df_info_filtered)\n",
    "    graph_baseline, dico_prophage_kltype_associated = TropiGAT_graph.build_graph_baseline(df_info_final)\n",
    "    \n",
    "    with ThreadPool(5) as p:\n",
    "        p.starmap(train_graph, [(kl_type, graph_baseline, dico_prophage_kltype_associated, df_info_final, dico_prophage_count) for kl_type in kltypes])\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08813690-2d60-44f5-8a4c-908273b39894",
   "metadata": {},
   "source": [
    "***\n",
    "### Move the best version of the model to local: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8b0b0145-bcd1-43d5-a4f9-e50a3f30a046",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "478e813b-d5a4-4d10-b991-811ac7f041bc",
   "metadata": {},
   "source": [
    "> Regular training :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "004bf918-910c-4e74-af99-13c248e21eae",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'KL1': '4', 'KL2': '3', 'KL3': '5', 'KL4': '5', 'KL5': '4', 'KL6': '3', 'KL7': '5', 'KL8': '1', 'KL9': '5', 'KL10': '4', 'KL12': '2', 'KL13': '1', 'KL14': '1', 'KL15': '1', 'KL16': '3', 'KL17': '2', 'KL18': '3', 'KL19': '5', 'KL20': '3', 'KL21': '3', 'KL22': '5', 'KL23': '5', 'KL24': '4', 'KL25': '4', 'KL26': '4', 'KL27': '4', 'KL28': '1', 'KL29': '4', 'KL30': '2', 'KL31': '1', 'KL34': '5', 'KL35': '3', 'KL36': '4', 'KL38': '5', 'KL39': '3', 'KL41': '3', 'KL43': '4', 'KL45': '5', 'KL46': '2', 'KL47': '5', 'KL48': '2', 'KL51': '2', 'KL52': '2', 'KL53': '2', 'KL54': '3', 'KL55': '5', 'KL56': '4', 'KL57': '2', 'KL60': '5', 'KL61': '3', 'KL62': '2', 'KL63': '3', 'KL64': '2', 'KL67': '4', 'KL70': '2', 'KL71': '3', 'KL74': '2', 'KL81': '1', 'KL102': '5', 'KL103': '3', 'KL105': '2', 'KL106': '3', 'KL107': '3', 'KL108': '4', 'KL109': '3', 'KL110': '1', 'KL111': '4', 'KL112': '5', 'KL114': '3', 'KL116': '2', 'KL117': '5', 'KL118': '1', 'KL122': '3', 'KL123': '2', 'KL124': '4', 'KL125': '3', 'KL127': '1', 'KL128': '1', 'KL136': '2', 'KL139': '2', 'KL140': '3', 'KL142': '2', 'KL143': '2', 'KL145': '3', 'KL149': '4', 'KL151': '5', 'KL152': '1', 'KL153': '4', 'KL155': '2', 'KL157': '4', 'KL166': '3', 'KL169': '3'}\n"
     ]
    }
   ],
   "source": [
    "average_metric_df = pd.read_csv(f\"/media/concha-eloko/Linux/PPT_clean/ficheros_28032023/Metric_Report.review.GAT.F.tsv\", sep = \"\\t\", index_col = False, header = 0)\n",
    "\n",
    "model_version = {kltype.split(\"_\")[0] : kltype.split(\"_\")[-1] for kltype in average_metric_df[\"model_version\"]}\n",
    "print(model_version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c20ebb58-f89a-4e29-bbbf-0aa565928c94",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "\n",
    "path_work = f\"/home/conchae/prediction_depolymerase_tropism/prophage_prediction/depolymerase_decipher/ficheros_28032023/train_nn\"\n",
    "path_best_models = f\"{path_work}/best_models\"\n",
    "path_models = f\"{path_work}/TropiGAT_ensemble_27_11_2024\"\n",
    "\n",
    "index = \"TropiGATv2.27_11_2024.pt\"\n",
    "\n",
    "model_version = {'KL1': '4', 'KL2': '3', 'KL3': '5', 'KL4': '5', 'KL5': '4', 'KL6': '3', 'KL7': '5', 'KL8': '1', 'KL9': '5', 'KL10': '4', 'KL12': '2', 'KL13': '1', 'KL14': '1', 'KL15': '1', 'KL16': '3', 'KL17': '2', 'KL18': '3', 'KL19': '5', 'KL20': '3', 'KL21': '3', 'KL22': '5', 'KL23': '5', 'KL24': '4', 'KL25': '4', 'KL26': '4', 'KL27': '4', 'KL28': '1', 'KL29': '4', 'KL30': '2', 'KL31': '1', 'KL34': '5', 'KL35': '3', 'KL36': '4', 'KL38': '5', 'KL39': '3', 'KL41': '3', 'KL43': '4', 'KL45': '5', 'KL46': '2', 'KL47': '5', 'KL48': '2', 'KL51': '2', 'KL52': '2', 'KL53': '2', 'KL54': '3', 'KL55': '5', 'KL56': '4', 'KL57': '2', 'KL60': '5', 'KL61': '3', 'KL62': '2', 'KL63': '3', 'KL64': '2', 'KL67': '4', 'KL70': '2', 'KL71': '3', 'KL74': '2', 'KL81': '1', 'KL102': '5', 'KL103': '3', 'KL105': '2', 'KL106': '3', 'KL107': '3', 'KL108': '4', 'KL109': '3', 'KL110': '1', 'KL111': '4', 'KL112': '5', 'KL114': '3', 'KL116': '2', 'KL117': '5', 'KL118': '1', 'KL122': '3', 'KL123': '2', 'KL124': '4', 'KL125': '3', 'KL127': '1', 'KL128': '1', 'KL136': '2', 'KL139': '2', 'KL140': '3', 'KL142': '2', 'KL143': '2', 'KL145': '3', 'KL149': '4', 'KL151': '5', 'KL152': '1', 'KL153': '4', 'KL155': '2', 'KL157': '4', 'KL166': '3', 'KL169': '3'}\n",
    "\n",
    "for kltype, version in model_version.items(): \n",
    "    #os.system(f\"mv {path_models}/{kltype}__{version}.{index} {path_best_models}/best_models_TropiGAT \")\n",
    "    os.system(f\"cp {path_best_models}/best_models_TropiGAT/{kltype}__{version}.{index} {path_models}\")\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b2ac502-848d-4bb3-a818-4bc5e58ef3ab",
   "metadata": {},
   "source": [
    "> Ultrafiltration : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b52e46d3-aae5-46e8-b98d-37e262f81e48",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'KL1': '3', 'KL2': '2', 'KL3': '5', 'KL4': '1', 'KL5': '1', 'KL6': '1', 'KL7': '5', 'KL8': '3', 'KL9': '3', 'KL10': '3', 'KL12': '4', 'KL13': '1', 'KL14': '3', 'KL15': '2', 'KL16': '4', 'KL17': '3', 'KL18': '5', 'KL19': '2', 'KL20': '3', 'KL21': '2', 'KL22': '4', 'KL23': '4', 'KL24': '2', 'KL25': '3', 'KL26': '4', 'KL27': '5', 'KL28': '5', 'KL29': '4', 'KL30': '3', 'KL31': '4', 'KL34': '5', 'KL35': '2', 'KL36': '5', 'KL38': '3', 'KL39': '3', 'KL43': '2', 'KL45': '3', 'KL46': '4', 'KL47': '4', 'KL48': '2', 'KL51': '3', 'KL52': '2', 'KL53': '4', 'KL55': '4', 'KL56': '2', 'KL57': '3', 'KL60': '4', 'KL62': '4', 'KL63': '3', 'KL64': '3', 'KL67': '4', 'KL70': '1', 'KL71': '1', 'KL74': '1', 'KL81': '2', 'KL102': '5', 'KL103': '3', 'KL105': '2', 'KL106': '5', 'KL107': '3', 'KL108': '5', 'KL109': '1', 'KL110': '1', 'KL111': '5', 'KL112': '5', 'KL114': '5', 'KL116': '2', 'KL117': '2', 'KL118': '4', 'KL122': '5', 'KL123': '4', 'KL124': '5', 'KL125': '3', 'KL127': '3', 'KL128': '4', 'KL136': '3', 'KL140': '4', 'KL142': '5', 'KL145': '2', 'KL149': '5', 'KL151': '1', 'KL153': '1', 'KL155': '2', 'KL157': '4', 'KL169': '5'}\n"
     ]
    }
   ],
   "source": [
    "average_metric_df = pd.read_csv(f\"/media/concha-eloko/Linux/PPT_clean/ficheros_28032023/Metric_Report.review.GAT.UF.tsv\", sep = \"\\t\", index_col = False, header = 0)\n",
    "\n",
    "model_version = {kltype.split(\"_\")[0] : kltype.split(\"_\")[-1] for kltype in average_metric_df[\"model_version\"]}\n",
    "print(model_version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bca79bd-ac2d-4c38-bcff-40696a816227",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "\n",
    "path_work = f\"/home/conchae/prediction_depolymerase_tropism/prophage_prediction/depolymerase_decipher/ficheros_28032023/train_nn\"\n",
    "path_best_models = f\"{path_work}/best_models\"\n",
    "path_models = f\"{path_work}/TropiGAT_ensemble_ultraF_27_11_2024\"\n",
    "\n",
    "index = \"TropiGATv2.27_11_2024.pt\"\n",
    "\n",
    "model_version = {'KL1': '3', 'KL2': '2', 'KL3': '5', 'KL4': '1', 'KL5': '1', 'KL6': '1', 'KL7': '5', 'KL8': '3', 'KL9': '3', 'KL10': '3', 'KL12': '4', 'KL13': '1', 'KL14': '3', 'KL15': '2', 'KL16': '4', 'KL17': '3', 'KL18': '5', 'KL19': '2', 'KL20': '3', 'KL21': '2', 'KL22': '4', 'KL23': '4', 'KL24': '2', 'KL25': '3', 'KL26': '4', 'KL27': '5', 'KL28': '5', 'KL29': '4', 'KL30': '3', 'KL31': '4', 'KL34': '5', 'KL35': '2', 'KL36': '5', 'KL38': '3', 'KL39': '3', 'KL43': '2', 'KL45': '3', 'KL46': '4', 'KL47': '4', 'KL48': '2', 'KL51': '3', 'KL52': '2', 'KL53': '4', 'KL55': '4', 'KL56': '2', 'KL57': '3', 'KL60': '4', 'KL62': '4', 'KL63': '3', 'KL64': '3', 'KL67': '4', 'KL70': '1', 'KL71': '1', 'KL74': '1', 'KL81': '2', 'KL102': '5', 'KL103': '3', 'KL105': '2', 'KL106': '5', 'KL107': '3', 'KL108': '5', 'KL109': '1', 'KL110': '1', 'KL111': '5', 'KL112': '5', 'KL114': '5', 'KL116': '2', 'KL117': '2', 'KL118': '4', 'KL122': '5', 'KL123': '4', 'KL124': '5', 'KL125': '3', 'KL127': '3', 'KL128': '4', 'KL136': '3', 'KL140': '4', 'KL142': '5', 'KL145': '2', 'KL149': '5', 'KL151': '1', 'KL153': '1', 'KL155': '2', 'KL157': '4', 'KL169': '5'}\n",
    "\n",
    "for kltype, version in model_version.items(): \n",
    "    #os.system(f\"mv {path_models}/{kltype}__{version}.{index} {path_best_models}/best_models_TropiGAT_UF \")\n",
    "    os.system(f\"cp {path_best_models}/best_models_TropiGAT_UF/{kltype}__{version}.{index} {path_models}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0693e243-75b3-4850-93d7-7b707792eb1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "rsync -avzhe ssh \\\n",
    "conchae@garnatxa.srv.cpd:/home/conchae/prediction_depolymerase_tropism/prophage_prediction/depolymerase_decipher/ficheros_28032023/train_nn/best_models \\\n",
    "/media/concha-eloko/Linux/PPT_clean/reviewed_models\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "conda-env-torch_geometric-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
