{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "128c018d-28f7-4307-880c-8a43a383703d",
   "metadata": {},
   "source": [
    "# Prediction with TropiSEQ :\n",
    "### I- Prepare the model\n",
    "### II- Run the predictions on matrices\n",
    "### III- Run the predictions on experimentally validated depolymerases¶\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "492286eb-b08e-412a-aafb-a79f78ac683a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Ground modules\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from Bio import SeqIO\n",
    "from itertools import product\n",
    "import random\n",
    "from collections import Counter\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "\n",
    "import logging\n",
    "import subprocess\n",
    "from multiprocessing.pool import ThreadPool\n",
    "import joblib\n",
    "import json\n",
    "\n",
    "# SCikitlearn modules :\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.metrics import classification_report , roc_auc_score\n",
    "\n",
    "# Scipy modules : \n",
    "from scipy.stats import fisher_exact"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a873f22-7aee-459d-8891-7f4aab78c0c7",
   "metadata": {},
   "source": [
    "> Set up predictor "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7d6ca2cb-cbd1-4740-82ca-34682d21417b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'\\n\\nBuilding a new DB, current time: 12/05/2024 15:56:05\\nNew DB name:   /media/concha-eloko/Linux/PPT_clean/Seqbased_model/TropiSeq/TropiLR_0.65.db\\nNew DB title:  /media/concha-eloko/Linux/PPT_clean/Seqbased_model/cdhit_clusters_2912/0.65.out\\nSequence type: Protein\\nKeep MBits: T\\nMaximum file size: 1000000000B\\nAdding sequences from FASTA; added 836 sequences in 0.172458 seconds.\\n' None\n"
     ]
    }
   ],
   "source": [
    "path_seqbased = \"/media/concha-eloko/Linux/PPT_clean/Seqbased_model\"\n",
    "path_db = f\"{path_seqbased}/TropiSeq/TropiLR_0.65.db\"\n",
    "path_work = \"/media/concha-eloko/Linux/PPT_clean\"\n",
    "path_benchmark = \"/media/concha-eloko/Linux/PPT_clean/benchmark\"\n",
    "\n",
    "# Run makeblast command :\n",
    "fasta_file = f\"{path_seqbased}/cdhit_clusters_2912/0.65.out\"\n",
    "\n",
    "blast_command = f\"makeblastdb -in {fasta_file} -dbtype prot -out {path_db}\"\n",
    "#make_blast_process = subprocess.Popen(blast_command, shell =True, stdout = subprocess.PIPE, stderr=subprocess.STDOUT)\n",
    "#mkblast_out, mkblast_err = make_blast_process.communicate()\n",
    "#print(mkblast_out , mkblast_err)\n",
    "\n",
    "# Relevant files :\n",
    "dico_cluster = json.load(open(f\"{path_seqbased}/dico_cluster.cdhit__0.65.json\"))\n",
    "dico_cluster_r = {ref_dpo : key_dpo for key_dpo,list_dpo in dico_cluster.items() for ref_dpo in list_dpo}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2f5ce6d4-f0a3-42eb-846d-28ed3c5fa21f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Relevant files :\n",
    "dico_cluster = json.load(open(f\"{path_seqbased}/dico_cluster.cdhit__0.65.json\"))\n",
    "dico_cluster_r = {ref_dpo : key_dpo for key_dpo,list_dpo in dico_cluster.items() for ref_dpo in list_dpo}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1b10f42-533a-4909-aa43-01daf8464872",
   "metadata": {},
   "source": [
    "> Load predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "570c73f8-4654-41f0-8442-9ecba3a0ca3a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "final_annotation = pd.read_csv(f\"/media/concha-eloko/Linux/PPT_clean/Seqbased_model/labeling_depo_clusters.pred.LogReg.tsv\", sep = \"\\t\", header = 0)\n",
    "\n",
    "final_annotation_tropiseq = final_annotation[final_annotation[\"TropiLR_KL_types\"] != \"None\"]\n",
    "final_annotation_tropiseq = final_annotation_tropiseq.drop_duplicates(subset = [\"depo_cluster\", \"TropiLR_KL_types\"])\n",
    "final_annotation_tropiseq = final_annotation_tropiseq[[\"depo_cluster\", \"TropiLR_KL_types\", \"TropiLR_scores\"]]\n",
    "\n",
    "dico_tropiseq_data = {row[\"depo_cluster\"] : {\"KL_types\" : row[\"TropiLR_KL_types\"], \"Scores\" : row[\"TropiLR_scores\"]} for _, row in final_annotation_tropiseq.iterrows()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9b3201a2-5239-453a-80e8-312bcac364bb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dico_pred = json.load(open(\"/media/concha-eloko/Linux/PPT_clean/Seqbased_model/prediction_based.labeling.LogReg.json\"))\n",
    "dico_pred_correct_name = {f\"Dpo_cdhit_{cluster.split('_')[1]}\":hits  for cluster, hits in dico_pred.items()}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0125550f-abc5-4ea6-bd9d-b48114a463d4",
   "metadata": {},
   "source": [
    "***\n",
    "### Run predictions on matrices: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b75d8588-935a-4ec9-9c80-f234939e3710",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "path_tmp =  \"/media/concha-eloko/Linux/PPT_clean/Seqbased_model/tmp\"\n",
    "labels_blast=[\"qseqid\", \"sseqid\", \"pident\", \"length\", \"mismatch\", \"gapopen\", \"qstart\", \"qend\", \"sstart\", \"send\", \"evalue\", \"bitscore\"]\n",
    "\n",
    "def tmp_fasta_file(record , path_tmp) :\n",
    "    name_file = \"_\".join(record.description.split(\" \"))\n",
    "    path_fasta = f\"{path_tmp}/{name_file}.fasta\"\n",
    "    length_seq = len(record.seq)\n",
    "    with open(path_fasta, \"w\") as outfile :\n",
    "        outfile.write(f\">{record.description}\\n{str(record.seq)}\")\n",
    "    return path_fasta , length_seq\n",
    "\n",
    "def blast_seq(path_fasta, path_DB, path_tmp) :\n",
    "    file_name = path_fasta.split(\"/\")[-1]\n",
    "    command = f\"blastp -query {path_fasta} -db {path_DB} -out {path_tmp}/{file_name}.blast_out -outfmt 6 -evalue 1e-10\"\n",
    "    blastp_sub = subprocess.Popen(command ,shell = True, stdout = subprocess.PIPE, stderr = subprocess.STDOUT)\n",
    "    out , err = blastp_sub.communicate()\n",
    "    return f\"{path_tmp}/{file_name}.blast_out\"\n",
    "\n",
    "def get_best_candidate(path_blast_out, length_seq, bitscore = 75) : \n",
    "    winner = 0\n",
    "    labels_blast=[\"qseqid\", \"sseqid\", \"pident\", \"length\", \"mismatch\", \"gapopen\", \"qstart\", \"qend\", \"sstart\", \"send\", \"evalue\", \"bitscore\"]\n",
    "    blast_df = pd.read_csv(path_blast_out, sep = \"\\t\", names = labels_blast)\n",
    "    if len(blast_df) > 0 :\n",
    "        row = blast_df.iloc[0] \n",
    "        if row[\"bitscore\"] > bitscore and length_seq/int(row[\"length\"])> 0.8:\n",
    "            winner = dico_cluster_r[row[\"sseqid\"]]\n",
    "        else :\n",
    "            winner = \"No hits\"\n",
    "    else :\n",
    "        winner = \"No hits\"\n",
    "    return winner\n",
    "\n",
    "def get_winner(record , path_tmp) :\n",
    "    path_func , len_func = tmp_fasta_file(record, path_tmp)\n",
    "    path_blast_out_func = blast_seq(path_func , path_db, path_tmp)\n",
    "    winner = get_best_candidate(path_blast_out_func, len_func)\n",
    "    return winner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "59a09d6a-cf82-41b9-b4fc-583dac1263df",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 145/145 [00:06<00:00, 22.12it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 71/71 [00:02<00:00, 24.32it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 44/44 [00:01<00:00, 24.91it/s]\n"
     ]
    }
   ],
   "source": [
    "# Ferriol inferences : \n",
    "path_seq = \"/media/concha-eloko/Linux/77_strains_phage_project/rbp_work\"\n",
    "dico_seq = {record.description : record.seq for record in SeqIO.parse(f\"{path_seq}/77_phages_Dpo_domains.2406.multi.fasta\", \"fasta\") if len(record.seq) >0}\n",
    "set_records = [record for record in SeqIO.parse(f\"{path_seq}/77_phages_Dpo_domains.2406.multi.fasta\", \"fasta\") if len(record.seq) > 0]\n",
    "\n",
    "\n",
    "ferriol_winners = []\n",
    "for record in tqdm(set_records) :\n",
    "    winner = get_winner(record, path_tmp)\n",
    "    if winner != \"No hits\" :\n",
    "        hit = int(winner.split(\"_\")[-1])\n",
    "        results = dico_pred_correct_name.get(winner, {})\n",
    "        a = (record.description.split(\",\")[0] , winner, results)\n",
    "    else :\n",
    "        results = \"Null\"\n",
    "    a = (record.description.split(\",\")[0] , winner, results)\n",
    "    ferriol_winners.append(a)\n",
    "    \n",
    "\n",
    "# ***************************************************************************\n",
    "# Beamud inferences : \n",
    "bea_winners = []\n",
    "path_bea = \"/media/concha-eloko/Linux/PPT_clean/in_vitro/Bea\"\n",
    "path_domains_bea = f\"{path_bea}/DepoScope_predictions.bea.domains.0709.fasta\"\n",
    "\n",
    "bea_dico_seq = {record.description : record.seq for record in SeqIO.parse(f\"{path_domains_bea}\", \"fasta\") if len(record.seq) >0}\n",
    "bea_set_records = [record for record in SeqIO.parse(f\"{path_domains_bea}\", \"fasta\") if len(record.seq) > 0]\n",
    "\n",
    "for record in tqdm(bea_set_records) :\n",
    "    winner = get_winner(record, path_tmp)\n",
    "    if winner != \"No hits\" :\n",
    "        hit = int(winner.split(\"_\")[-1])\n",
    "        results = dico_pred_correct_name.get(winner, {})\n",
    "        a = (record.description.split(\",\")[0] , winner, results)\n",
    "    else :\n",
    "        results = \"Null\"\n",
    "    a = (record.description.split(\",\")[0] , winner, results)\n",
    "    bea_winners.append(a)\n",
    "    \n",
    "    \n",
    "# ***************************************************************************\n",
    "# Towndsend inferences : \n",
    "towndsend_winners = []\n",
    "path_towndsend = \"/media/concha-eloko/Linux/PPT_clean/in_vitro/Townsed\"\n",
    "path_domains_towndsend = f\"{path_towndsend}/DepoScope_predictions.Townsed.domains.0909.fasta\"\n",
    "\n",
    "towndsend_dico_seq = {record.description : record.seq for record in SeqIO.parse(f\"{path_domains_towndsend}\", \"fasta\") if len(record.seq) >0}\n",
    "towndsend_set_records = [record for record in SeqIO.parse(f\"{path_domains_towndsend}\", \"fasta\") if len(record.seq) > 0]\n",
    "\n",
    "for record in tqdm(towndsend_set_records) :\n",
    "    winner = get_winner(record, path_tmp)\n",
    "    if winner != \"No hits\" :\n",
    "        hit = int(winner.split(\"_\")[-1])\n",
    "        results = dico_pred_correct_name.get(winner, {})\n",
    "        a = (record.description.split(\",\")[0] , winner, results)\n",
    "    else :\n",
    "        results = \"Null\"\n",
    "    a = (record.description.split(\",\")[0] , winner, results)\n",
    "    towndsend_winners.append(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7a598564-1c5a-4710-b05d-0bf6ae287f97",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "TropiLR_results = ferriol_winners + towndsend_winners + bea_winners\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e73c23a4-57b6-423f-a6ce-f53df18340f9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(f\"{path_benchmark}/TropiLogReg.matrices.tsv\" , \"w\") as outfile :\n",
    "    for prot in TropiLR_results :\n",
    "        prot_name = prot[0].split(\"_A\")[0]\n",
    "        if prot[1] == \"No hits\" :\n",
    "            outfile.write(f\"{prot_name}\\tNo_hits\\n\")\n",
    "        elif prot[2] == {} :\n",
    "            outfile.write(f\"{prot_name}\\tNo_associations\\n\")\n",
    "        else :\n",
    "            try :\n",
    "                hits = [f\"{kltype}:{round(score,3)}\" for kltype, score in prot[2].items()]\n",
    "                outfile.write(f\"{prot_name}\\t\")\n",
    "                outfile.write(\" ; \".join(hits))\n",
    "                outfile.write(\"\\n\")\n",
    "            except Exception as e :\n",
    "                print(prot, e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9ca0620-2aa0-42f2-beef-7f0b325bf4ce",
   "metadata": {},
   "source": [
    "***\n",
    "### Work on experimentally validated depolymerases :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "527974d0-72c5-4930-9a72-c244328097df",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 56/56 [00:02<00:00, 23.31it/s]\n"
     ]
    }
   ],
   "source": [
    "# ***************************************************************************\n",
    "# exp_validated inferences : \n",
    "exp_validated_winners = []\n",
    "path_seq = \"/media/concha-eloko/Linux/PPT_clean/in_vitro\"\n",
    "\n",
    "dico_seq = {record.description : record.seq for record in SeqIO.parse(f\"{path_seq}/Others_all.dpos_domains.multi.fasta\", \"fasta\") if len(record.seq) >0}\n",
    "exp_validated_set_records = [record for record in SeqIO.parse(f\"{path_seq}/Others_all.dpos_domains.multi.fasta\", \"fasta\") if len(record.seq) > 0]\n",
    "\n",
    "\n",
    "for record in tqdm(exp_validated_set_records) :\n",
    "    winner = get_winner(record, path_tmp)\n",
    "    if winner != \"No hits\" :\n",
    "        hit = int(winner.split(\"_\")[-1])\n",
    "        results = dico_pred_correct_name.get(winner, {})\n",
    "        a = (record.description.split(\",\")[0] , winner, results)\n",
    "    else :\n",
    "        results = \"Null\"\n",
    "    a = (record.description.split(\",\")[0] , winner, results)\n",
    "    exp_validated_winners.append(a)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a814fd30-69a1-4f42-bf15-78c4562f0d53",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(f\"{path_benchmark}/TropiLogReg.exp_val_depolymerase.tsv\" , \"w\") as outfile :\n",
    "    for prot in exp_validated_winners :\n",
    "        prot_name = prot[0].split(\"_A\")[0]\n",
    "        if prot[1] == \"No hits\" :\n",
    "            outfile.write(f\"{prot_name}\\tNo_hits\\n\")\n",
    "        elif prot[2] == {} :\n",
    "            outfile.write(f\"{prot_name}\\tNo_associations\\n\")\n",
    "        else :\n",
    "            try :\n",
    "                hits = [f\"{kltype}:{round(score,3)}\" for kltype, score in prot[2].items()]\n",
    "                outfile.write(f\"{prot_name}\\t\")\n",
    "                outfile.write(\" ; \".join(hits))\n",
    "                outfile.write(\"\\n\")\n",
    "            except Exception as e :\n",
    "                print(prot, e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7c89118-cdae-4aaa-955d-cc8f83d49efa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ML_work_v2]",
   "language": "python",
   "name": "conda-env-ML_work_v2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
