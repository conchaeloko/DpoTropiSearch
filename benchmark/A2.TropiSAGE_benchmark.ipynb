{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0507b22f-4380-4d41-a9a2-09ad3b5eaa97",
   "metadata": {},
   "source": [
    "# Prediction with TropiGAT : \n",
    "### I- Prepare the model\n",
    "### II- Run the predictions on matrices\n",
    "### III- Run the predictions on experimentally validated depolymerases\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3161dbda-a67f-41b8-9c9e-1a5dbfa4ec3a",
   "metadata": {},
   "source": [
    "### Prepare the model: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dd8385e0-05a1-420f-991a-d464d9b13b99",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/concha-eloko/Linux/conda_envs/torch_geometric/lib/python3.11/site-packages/torch_geometric/typing.py:18: UserWarning: An issue occurred while importing 'pyg-lib'. Disabling its usage. Stacktrace: /media/concha-eloko/Linux/conda_envs/torch_geometric/lib/python3.11/site-packages/libpyg.so: undefined symbol: _ZN3c1010Dispatcher17runRecordFunctionERN2at14RecordFunctionESt17reference_wrapperIKNS_14FunctionSchemaEENS_11DispatchKeyE\n",
      "  warnings.warn(f\"An issue occurred while importing 'pyg-lib'. \"\n",
      "/media/concha-eloko/Linux/conda_envs/torch_geometric/lib/python3.11/site-packages/torch_geometric/typing.py:31: UserWarning: An issue occurred while importing 'torch-scatter'. Disabling its usage. Stacktrace: /media/concha-eloko/Linux/conda_envs/torch_geometric/lib/python3.11/site-packages/torch_scatter/_version_cpu.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev\n",
      "  warnings.warn(f\"An issue occurred while importing 'torch-scatter'. \"\n",
      "/media/concha-eloko/Linux/conda_envs/torch_geometric/lib/python3.11/site-packages/torch_geometric/typing.py:42: UserWarning: An issue occurred while importing 'torch-sparse'. Disabling its usage. Stacktrace: /media/concha-eloko/Linux/conda_envs/torch_geometric/lib/python3.11/site-packages/torch_sparse/_version_cpu.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev\n",
      "  warnings.warn(f\"An issue occurred while importing 'torch-sparse'. \"\n",
      "/media/concha-eloko/Linux/conda_envs/torch_geometric/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.data import HeteroData, DataLoader\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.nn import to_hetero , HeteroConv , GATv2Conv\n",
    "from torch_geometric.utils import negative_sampling\n",
    "from torch_geometric.loader import LinkNeighborLoader\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.preprocessing import LabelEncoder , label_binarize , OneHotEncoder\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score , matthews_corrcoef\n",
    "\n",
    "import TropiGAT_functions \n",
    "#from TropiGAT_functions import get_top_n_kltypes ,clean_print \n",
    "\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from itertools import product\n",
    "import random\n",
    "from collections import Counter\n",
    "import warnings\n",
    "import logging\n",
    "from multiprocessing.pool import ThreadPool\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# *****************************************************************************\n",
    "# Load the Dataframes :\n",
    "path_benchmark = \"/media/concha-eloko/Linux/PPT_clean/benchmark\"\n",
    "\n",
    "path_work = \"/media/concha-eloko/Linux/PPT_clean/reviewed_models/best_models\"\n",
    "\n",
    "# Load best parameters : \n",
    "with open(f\"/media/concha-eloko/Linux/PPT_clean/trainer_best_parameters/DAG_models_best_para.json\", \"r\") as f:\n",
    "    best_parameters = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83a2a6c5-e6e7-4dc5-af51-10a7b89fd0b5",
   "metadata": {},
   "source": [
    "> TropiSAGE regular:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "85b97ab1-a013-4180-8682-47584f9887be",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_ensemble = f\"{path_work}/best_models_TropiSAGE\"\n",
    "\n",
    "dico_models, errors = TropiGAT_functions.make_ensemble_TropiSAGE_r(path_ensemble)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb1991a3-b22c-433d-adb4-496825456dcf",
   "metadata": {},
   "source": [
    "> TropiSAGE ultrafiltration: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a18c5d9a-912b-446e-b524-0fc076eb1b66",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "path_ensemble = f\"{path_work}/best_models_TropiSAGE_UF\"\n",
    "\n",
    "dico_models, errors = TropiGAT_functions.make_ensemble_TropiSAGE_r(path_ensemble)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df48a48b-d732-42c0-8e42-3e700695aff4",
   "metadata": {},
   "source": [
    "***\n",
    "### Run predictions on matrices: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0c8cf390-fea9-4b34-b9de-7425a299facf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ***************************************************************************\n",
    "# Ferriol inferences : \n",
    "path_project = \"/media/concha-eloko/Linux/77_strains_phage_project\"\n",
    "path_Dpo_domain_org = \"/media/concha-eloko/Linux/depolymerase_building/clean_77_phages_depo\"\n",
    "\n",
    "dpo_embeddings = pd.read_csv(f\"{path_project}/rbp_work/Dpo_domains_77.esm2.embedding.2406.csv\", sep = \",\" , header = None, index_col = 0)\n",
    "\n",
    "\n",
    "# ***************************************************************************\n",
    "# Beamud inferences : \n",
    "path_project = \"/media/concha-eloko/Linux/PPT_clean/in_vitro\"\n",
    "\n",
    "bea_embeddings = pd.read_csv(f\"{path_project}/Bea_phages.esm2.embedding.csv\", sep = \",\" , header = None)\n",
    "bea_embeddings = bea_embeddings.drop([1281] , axis = 1)\n",
    "bea_embeddings.set_index([0], inplace = True)\n",
    "\n",
    "\n",
    "# ***************************************************************************\n",
    "# Towndsend inferences : \n",
    "path_project = \"/media/concha-eloko/Linux/PPT_clean/in_vitro\"\n",
    "\n",
    "towndsend_embeddings = pd.read_csv(f\"{path_project}/Townsed_phages.esm2.embedding.1112.csv\", sep = \",\" , header = None)\n",
    "towndsend_embeddings = towndsend_embeddings.drop([1281] , axis = 1)\n",
    "towndsend_embeddings.set_index([0], inplace = True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f0b26c8-f929-4004-ad75-1e4ca61665e8",
   "metadata": {},
   "source": [
    "> Run the predictions :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "080a8d18-0bc3-4f8c-a7ab-62a314eb946d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 143/143 [00:12<00:00, 11.58it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 71/71 [00:06<00:00, 11.13it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 45/45 [00:03<00:00, 14.60it/s]\n"
     ]
    }
   ],
   "source": [
    "# Run the predictions ferriol :\n",
    "ferriol_predictions = {}\n",
    "for dpo in tqdm(dpo_embeddings.index) : \n",
    "    try : \n",
    "        graph_dpo = TropiGAT_functions.make_query_graph([dpo_embeddings.loc[dpo].values])\n",
    "        pred = TropiGAT_functions.run_prediction(graph_dpo,dico_models)\n",
    "        ferriol_predictions[dpo] = pred\n",
    "    except Exception as e :\n",
    "        print(dpo, e)\n",
    "        \n",
    "# Run the predictions Bea :\n",
    "bea_predictions = {}\n",
    "for dpo in tqdm(bea_embeddings.index) : \n",
    "    graph_dpo = TropiGAT_functions.make_query_graph([bea_embeddings.loc[dpo].values])\n",
    "    pred = TropiGAT_functions.run_prediction(graph_dpo,dico_models)\n",
    "    bea_predictions[dpo] = pred\n",
    "    \n",
    "# Run the predictions towndsend :\n",
    "towndsend_predictions = {}\n",
    "for dpo in tqdm(towndsend_embeddings.index) : \n",
    "    graph_dpo = TropiGAT_functions.make_query_graph([towndsend_embeddings.loc[dpo].values])\n",
    "    pred = TropiGAT_functions.run_prediction(graph_dpo,dico_models)\n",
    "    towndsend_predictions[dpo] = pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56fabc28-79f8-4c17-a702-d3b904755766",
   "metadata": {},
   "source": [
    "> Write the file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2c08c56f-2eef-4ca0-a46d-8dec1267b524",
   "metadata": {},
   "outputs": [],
   "source": [
    "for prot in ferriol_predictions:\n",
    "    if prot == \"K42PH8_Dpo_domain\": \n",
    "        ferriol_predictions[\"K42PH8__cds_48_Dpo_domain\"] = ferriol_predictions[prot]\n",
    "        del ferriol_predictions[prot]\n",
    "        break\n",
    "        \n",
    "        \n",
    "predictions = [ferriol_predictions , bea_predictions , towndsend_predictions]\n",
    "\n",
    "        \n",
    "with open(f\"{path_benchmark}/TropiSAGE_UF.review.matrices.tsv\", \"w\") as outfile:\n",
    "    for prediction in predictions:\n",
    "        for prot in prediction:\n",
    "            if prediction[prot] == \"No hits\" or len(prediction[prot]) == 0:\n",
    "                outfile.write(f\"{prot}\\tNo hits\\n\")\n",
    "            else:\n",
    "                outfile.write(f\"{prot}\\t\")\n",
    "                hits = [f\"{kltype}:{round(score, 3)}\" for kltype, score in prediction[prot].items()]\n",
    "                sorted_hits = \" ; \".join(sorted(hits, key=lambda x: float(x.split(\":\")[1]), reverse=True))\n",
    "                outfile.write(sorted_hits)\n",
    "                outfile.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b013956a-f240-45c7-81cc-8c8acc1d0c0a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "142"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ferriol_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccee9b43-5246-48be-bb23-60a2868f4e6f",
   "metadata": {},
   "source": [
    "***\n",
    "### Work on experimentally validated depolymerases:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e8063aae-9487-4e37-8926-a56507d4136d",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_project = \"/media/concha-eloko/Linux/PPT_clean/in_vitro\"\n",
    "\n",
    "others_embeddings = pd.read_csv(f\"{path_project}/Others_all.esm2.embedding.csv\", sep = \",\" , header = None)\n",
    "others_embeddings.set_index([0], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "45d16ea7-54d3-43b6-9c17-d496a2fc5d2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22it [00:01, 16.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running_mean should contain 1 elements not 1280 ON146449.1_prot_UPW35150.1_13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "32it [00:02, 14.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running_mean should contain 1 elements not 1280 ON146449.1_prot_UPW35138.1_1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "56it [00:04, 12.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running_mean should contain 1 elements not 1280 ON146449.1_prot_UPW35150.1_13\n",
      "running_mean should contain 1 elements not 1280 ON146449.1_prot_UPW35138.1_1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Run the predictions Others :\n",
    "other_predictions = {}\n",
    "for index, dpo in tqdm(enumerate(others_embeddings.index)) :\n",
    "    if dpo not in [\"MN781108.1_prot_QGZ15323.1_262\"] :\n",
    "        try : \n",
    "            graph_dpo = TropiGAT_functions.make_query_graph([others_embeddings.loc[dpo].values])\n",
    "            pred = TropiGAT_functions.run_prediction(graph_dpo,dico_models)\n",
    "            other_predictions[dpo] = pred\n",
    "        except Exception as e :\n",
    "            print(e, dpo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dfc714b1-2bce-48a8-8be1-b4fac68240ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = [other_predictions]\n",
    "\n",
    "with open(f\"{path_benchmark}/TropiSAGE_UF.review.exp_val_depolymerase.tsv\", \"w\") as outfile:\n",
    "    for prediction in predictions:\n",
    "        prediction_sorted = dict(sorted(prediction.items()))\n",
    "        for prot in prediction_sorted:\n",
    "            if prediction_sorted[prot] == \"No hits\" or len(prediction_sorted[prot]) == 0:\n",
    "                outfile.write(f\"{prot}\\tNo hits\\n\")\n",
    "            else:\n",
    "                outfile.write(f\"{prot}\\t\")\n",
    "                hits = [f\"{kltype}:{round(score, 3)}\" for kltype, score in prediction_sorted[prot].items()]\n",
    "                sorted_hits = \" ; \".join(sorted(hits, key=lambda x: float(x.split(\":\")[1]), reverse=True))\n",
    "                outfile.write(sorted_hits)\n",
    "                outfile.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e55db58e-fed2-4fef-b84f-3ed11c283c1b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:torch_geometric]",
   "language": "python",
   "name": "conda-env-torch_geometric-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
